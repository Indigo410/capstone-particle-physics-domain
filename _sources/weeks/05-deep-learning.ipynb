{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 5 Notebook: Building a Deep Learning Model\n",
    "===============================================================\n",
    "\n",
    "Now, we'll look at a deep learning model based on low-level track features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 48 track-level features\n",
    "features = ['track_pt',\n",
    "            'track_ptrel',\n",
    "            'trackBTag_Eta',\n",
    "            'trackBTag_DeltaR',\n",
    "            'trackBTag_EtaRel',\n",
    "            'trackBTag_JetDistVal',\n",
    "            'trackBTag_Momentum',\n",
    "            'trackBTag_PPar',\n",
    "            'trackBTag_PParRatio',\n",
    "            'trackBTag_PtRatio',\n",
    "            'trackBTag_PtRel',\n",
    "            'trackBTag_Sip2dSig',\n",
    "            'trackBTag_Sip2dVal',\n",
    "            'trackBTag_Sip3dSig',\n",
    "            'trackBTag_Sip3dVal',\n",
    "            'track_VTX_ass',\n",
    "            'track_charge',\n",
    "            'track_deltaR',\n",
    "            'track_detadeta',\n",
    "            'track_dlambdadz',\n",
    "            'track_dlambdadz',\n",
    "            'track_dphidphi',\n",
    "            'track_dphidxy',\n",
    "            'track_dptdpt',\n",
    "            'track_drminsv',\n",
    "            'track_drsubjet1',\n",
    "            'track_drsubjet2',\n",
    "            'track_dxy',\n",
    "            'track_dxydxy',\n",
    "            'track_dxydz',\n",
    "            'track_dxysig',\n",
    "            'track_dz',\n",
    "            'track_dzdz',        \n",
    "            'track_dzsig',\n",
    "            'track_erel',\n",
    "            'track_etarel',\n",
    "            'track_fromPV',\n",
    "            'track_isChargedHad',\n",
    "            'track_isEl',\n",
    "            'track_isMu',\n",
    "            'track_lostInnerHits',\n",
    "            'track_mass',\n",
    "            'track_normchi2',            \n",
    "            'track_phirel',\n",
    "            'track_pt',\n",
    "            'track_ptrel',\n",
    "            'track_puppiw',\n",
    "            'track_quality']\n",
    "\n",
    "# spectators to define mass/pT window\n",
    "spectators = ['fj_sdmass',\n",
    "              'fj_pt']\n",
    "\n",
    "# 2 labels: QCD or Hbb (we'll reduce the following labels)\n",
    "labels =  ['label_QCD_b',\n",
    "           'label_QCD_bb',\n",
    "           'label_QCD_c', \n",
    "           'label_QCD_cc', \n",
    "           'label_QCD_others',\n",
    "           'sample_isQCD',\n",
    "           'label_H_bb']\n",
    "\n",
    "nfeatures = len(features)\n",
    "nspectators = len(spectators)\n",
    "nlabels = 2\n",
    "\n",
    "# we're going to zero-pad up to 60 tracks\n",
    "ntracks = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators\n",
    "\n",
    "A quick aside on data generators. As training on large datasets is a key component of many deep learning approaches (and especially in high energy physics), and these datasets no longer fit in memory, it is imporatant to write a data generator which can automatically fetch data.\n",
    "\n",
    "Here we modify one from: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DataGenerator in module DataGenerator:\n",
      "\n",
      "class DataGenerator(keras.utils.data_utils.Sequence)\n",
      " |  DataGenerator(list_files, features, labels, spectators, batch_size=1024, n_dim=60, remove_mass_pt_window=False, remove_unlabeled=True, return_spectators=False, max_entry=20000)\n",
      " |  \n",
      " |  Generates data for Keras\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DataGenerator\n",
      " |      keras.utils.data_utils.Sequence\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Generate one batch of data\n",
      " |  \n",
      " |  __init__(self, list_files, features, labels, spectators, batch_size=1024, n_dim=60, remove_mass_pt_window=False, remove_unlabeled=True, return_spectators=False, max_entry=20000)\n",
      " |      Initialization\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Denotes the number of batches per epoch\n",
      " |  \n",
      " |  on_epoch_end(self)\n",
      " |      Updates indexes after each epoch\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.utils.data_utils.Sequence:\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Create a generator that iterate over the Sequence.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.utils.data_utils.Sequence:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from keras.utils.data_utils.Sequence:\n",
      " |  \n",
      " |  use_sequence_api = True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from DataGenerator import DataGenerator\n",
    "help(DataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training and validation generators \n",
    "train_files = ['root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/train/ntuple_merged_10.root']\n",
    "val_files = ['root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/train/ntuple_merged_11.root']\n",
    "\n",
    "\n",
    "train_generator = DataGenerator(train_files, features, labels, spectators, batch_size=1024, n_dim=ntracks, \n",
    "                                remove_mass_pt_window=False, \n",
    "                                remove_unlabeled=True, max_entry=5000)\n",
    "\n",
    "val_generator = DataGenerator(val_files, features, labels, spectators, batch_size=1024, n_dim=ntracks, \n",
    "                                remove_mass_pt_window=False, \n",
    "                                remove_unlabeled=True, max_entry=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data Generator\n",
    "Note that the track array has a different \"shape.\" There are also slightly less than the requested `batch_size=1024` because we remove unlabeled samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 60, 48)\n",
      "(943, 2)\n"
     ]
    }
   ],
   "source": [
    "X, y = train_generator[0]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this generator can be optimized further (storing the data file locally, etc.). It's important to note that I/O is often a bottleneck for training big networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 60, 48)            0         \n",
      "_________________________________________________________________\n",
      "bn_1 (BatchNormalization)    (None, 60, 48)            192       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2880)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                184384    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 187,778\n",
      "Trainable params: 187,682\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, BatchNormalization, Conv1D, Flatten, Lambda\n",
    "import keras.backend as K\n",
    "\n",
    "# define dense keras model\n",
    "inputs = Input(shape=(ntracks,nfeatures,), name = 'input')  \n",
    "x = BatchNormalization(name='bn_1')(inputs)\n",
    "x = Flatten(name='flatten_1')(x)\n",
    "x = Dense(64, name = 'dense_1', activation='relu')(x)\n",
    "x = Dense(32, name = 'dense_2', activation='relu')(x)\n",
    "x = Dense(32, name = 'dense_3', activation='relu')(x)\n",
    "outputs = Dense(nlabels, name = 'output', activation='softmax')(x)\n",
    "keras_model_dense = Model(inputs=inputs, outputs=outputs)\n",
    "keras_model_dense.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(keras_model_dense.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "reduce_lr = ReduceLROnPlateau(patience=5,factor=0.5)\n",
    "model_checkpoint = ModelCheckpoint('keras_model_dense_best.h5', monitor='val_loss', save_best_only=True)\n",
    "callbacks = [early_stopping, model_checkpoint, reduce_lr]\n",
    "\n",
    "# fit keras model\n",
    "history_dense = keras_model_dense.fit_generator(train_generator, \n",
    "                                                validation_data = val_generator, \n",
    "                                                steps_per_epoch=len(train_generator), \n",
    "                                                validation_steps=len(val_generator),\n",
    "                                                max_queue_size=5,\n",
    "                                                epochs=100, \n",
    "                                                shuffle=False,\n",
    "                                                callbacks = callbacks, \n",
    "                                                verbose=0)\n",
    "# reload best weights\n",
    "keras_model_dense.load_weights('keras_model_dense_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAqfUlEQVR4nO3de3ycZZn/8c81k8k5TU+hp7RNsYXSQk+EUqgKKGgrSkFZaBc5rAd+8JPVlX254h5QcfmtKB4Wl3VlFRcQrYiHrVKoCAiogA21FHqk9Jge09IkbdM0ycz1++OZpJM0aSbtJJOZfN+v17zmee7ndD2Z9pp77ud+7sfcHRERyXyhdAcgIiKpoYQuIpIllNBFRLKEErqISJZQQhcRyRJK6CIiWSKphG5m88xsvZltNLM7Oln+LTNbGX9tMLPalEcqIiInZN31QzezMLABuAyoBpYDi9x9TRfr/y0w090/dqL9Dh8+3CsqKk4mZhGRAevVV1/d5+5lnS3LSWL72cBGd98EYGaLgQVApwkdWAR8sbudVlRUUFVVlcThRUSklZlt7WpZMk0uY4DtCfPV8bLODjQemAA828Xym82sysyqampqkji0iIgkK9UXRRcCj7t7tLOF7v6Au1e6e2VZWae/GERE5CQlk9B3AGMT5svjZZ1ZCPzkVIMSEZGeS6YNfTkwycwmECTyhcBfd1zJzCYDQ4CXUhqhiGSF5uZmqquraWxsTHcoGSE/P5/y8nIikUjS23Sb0N29xcxuA5YBYeBBd19tZncBVe6+JL7qQmCxa/hGEelEdXU1JSUlVFRUYGbpDqdfc3f2799PdXU1EyZMSHq7ZGrouPtSYGmHsjs7zH8p6aOKyIDT2NioZJ4kM2PYsGH0tPOI7hQVkT6jZJ68k/lbZVxCX77lbe5dtp5oTC07IiKJMi6hr9xWy388t5EjzZ32jBQR6VJxcXG6Q+hVGZfQ83PDABxpUkIXEUmUcQm9IBIk9EbV0EUkBVauXMmcOXOYNm0aV111FQcOHADgvvvuY8qUKUybNo2FCxcC8PzzzzNjxgxmzJjBzJkzOXjwYDpDP05SvVz6k9aEriYXkcz15V+vZs3O+pTuc8roQXzxQ1N7vN0NN9zAd77zHS666CLuvPNOvvzlL/Ptb3+br371q2zevJm8vDxqa2sBuPfee7n//vuZO3cuhw4dIj8/P6XncKoyr4aeG4SsJhcROVV1dXXU1tZy0UUXAXDjjTfywgsvADBt2jSuu+46fvSjH5GTE9R9586dy+233859991HbW1tW3l/0b+iSUK+augiGe9katJ97YknnuCFF17g17/+NXfffTevv/46d9xxB5dffjlLly5l7ty5LFu2jMmTJ6c71DaZV0NXQheRFCktLWXIkCG8+OKLADzyyCNcdNFFxGIxtm/fziWXXMI999xDXV0dhw4d4q233uKcc87h85//POeddx7r1q1L8xm0l3E19IJ4L5dGNbmISA81NDRQXl7eNn/77bfz0EMPccstt9DQ0MDpp5/OD3/4Q6LRKB/96Eepq6vD3fn0pz/N4MGD+Zd/+Reee+45QqEQU6dOZf78+Wk8m+NlXEIvjAQhq4YuIj0Vi8U6LX/55ZePK/vDH/5wXNl3vvOdlMeUShnX5JLfelFUCV1EpJ2MS+htbehqchERaSfjEnq+biwSEelUxiX0SDhEJGxqchER6SDjEjoEtfQjTZ1f3BARGagyMqEXRMKqoYuIdJCZCT03rDZ0EemRSy65hGXLlrUr+/a3v82tt97a5TYXX3wxVVVVJ9zvl770Je69996UxHiqMjOhR8Lq5SIiPbJo0SIWL17crmzx4sUsWrQoTRGlXkYm9PxImAbV0EWkB66++mqeeOIJmpqaANiyZQs7d+7kXe96F7feeiuVlZVMnTqVL37xiyd9jHQPxZtxd4pCUEPXrf8iGezJO2D366nd58hzYP5Xu1w8dOhQZs+ezZNPPsmCBQtYvHgx11xzDWbG3XffzdChQ4lGo7z3ve9l1apVTJs2rcchpHso3qRq6GY2z8zWm9lGM7uji3WuMbM1ZrbazH58ypGdQEGuLoqKSM8lNrskNrc89thjzJo1i5kzZ7J69WrWrFnT4333h6F4u92DmYWB+4HLgGpguZktcfc1CetMAr4AzHX3A2Z22ilHdgLq5SKS4U5Qk+5NCxYs4LOf/SwrVqygoaGBc889l82bN3PvvfeyfPlyhgwZwk033URjY2NKj9tXQ/EmU0OfDWx0903u3gQsBhZ0WOeTwP3ufgDA3feeUlTdyNdFURE5CcXFxVxyySV87GMfa6ud19fXU1RURGlpKXv27OHJJ588qX33h6F4k6njjwG2J8xXA+d3WOcMADP7IxAGvuTuT3XckZndDNwMMG7cuJOJFwieWqRuiyJyMhYtWsRVV13V1vQyffp0Zs6cyeTJkxk7dixz587tdLtPfOIT3HLLLVRWVna573QPxWvufuIVzK4G5rn7J+Lz1wPnu/ttCev8BmgGrgHKgReAc9y9tqv9VlZWenf9O7ty9xNrePSVbay5a95JbS8ifW/t2rWcddZZ6Q4jo3T2NzOzV92902+VZJpcdgBjE+bL42WJqoEl7t7s7puBDcCkpKPuodY29O6+jEREBpJkEvpyYJKZTTCzXGAhsKTDOr8CLgYws+EETTCbUhdme/m5YdzhaIvGcxERadVtQnf3FuA2YBmwFnjM3Veb2V1mdkV8tWXAfjNbAzwHfM7d9/dW0AUaQlckI+lXdfJO5m+VVMdHd18KLO1QdmfCtAO3x1+9LvFB0YP74oAicsry8/PZv38/w4YNw8zSHU6/5u7s37+/xzcbZeadorl6apFIpikvL6e6upqampp0h5IR8vPz2z3QOhkZmdDzE2roIpIZIpEIEyZMSHcYWS0jB+dSG7qIyPEyM6G3Nbmol4uISKvMTOhqchEROU5GJnS1oYuIHC8jE3prk4vGRBcROSYzE7pq6CIix1FCFxHJEhmZ0PNygrB1Y5GIyDEZmdBDISM/ojHRRUQSZWRCBz2GTkSko8xO6GpyERFpk7EJPT9XNXQRkUQZm9ALImG1oYuIJMjohK4auojIMZmb0HPDNKgNXUSkTeYmdF0UFRFpJ3MTeq7a0EVEEmVuQlcbuohIOxmb0PPV5CIi0k5SCd3M5pnZejPbaGZ3dLL8JjOrMbOV8dcnUh9qe0GTi55YJCLSqtuHRJtZGLgfuAyoBpab2RJ3X9Nh1Z+6+229EGOnCiJhmqIxWqIxcsIZ+0NDRCRlksmEs4GN7r7J3ZuAxcCC3g2re20Pim5RLV1EBJJL6GOA7Qnz1fGyjj5iZqvM7HEzG5uS6E4gv+1B0WpHFxGB1F0U/TVQ4e7TgKeBhzpbycxuNrMqM6uqqak5pQO21dDV00VEBEguoe8AEmvc5fGyNu6+392Pxme/D5zb2Y7c/QF3r3T3yrKyspOJt42eWiQi0l4yCX05MMnMJphZLrAQWJK4gpmNSpi9AlibuhA7V5CrpxaJiCTqNqG7ewtwG7CMIFE/5u6rzewuM7sivtqnzWy1mb0GfBq4qbcC5s2n4eefJL/1MXSqoYuIAEl0WwRw96XA0g5ldyZMfwH4QmpD60L9Tnj9MQZPuhlQQhcRaZV5Hbgr3gnA0Jo/A9CoJhcRESATE/rQ06F4JCW7XwFUQxcRaZV5Cd0MKuaSv/NlwJXQRUTiMi+hA1S8k/DhPVTYbvVyERGJy8yEPj5oRz8/tE43FomIxGVmQh8+CYpO44LQWjW5iIjEZWZCN4PxF3J+aC1Hjiqhi4hApiZ0gIp3Msr2k99Qne5IRET6hcxN6OPnAjC27tU0ByIi0j9kbkIvm0ydlVBxaGW6IxER6RcyN6GHQqyJnMPEhtfSHYmISL+QuQkdWJ8/jbLobqjd3v3KIiJZLqMT+qai6cHEtpfSG4iISD+Q0Ql9f9FEDlEEW/+Y7lBERNIuoxN6Xm4uq0KTYeuf0h2KiEjaZXRCL4iEqfLJsG8DHDq1Z5SKiGS6jE/oL0UnBzNqRxeRAS6zE3pumFebx+M5BWp2EZEBL6MTen4kTJPnEBtTCduU0EVkYMvohF4QCQPQPGYO7H4dGuvSHJGISPpkdEIvygsSev2I88BjsP3Pna/YWN+HUYmIpEdGJ/QzRpQA8JpPhFDO8e3oTYfhqS/AV8fBYzfA4f1piFJEpG8kldDNbJ6ZrTezjWZ2xwnW+4iZuZlVpi7Erk0dXUpuTog/7zgKo2ceS+jusOn38N0L4eX/hDPeD+uWwn+eD2t/0xehiYj0uW4TupmFgfuB+cAUYJGZTelkvRLgM8ArqQ6yK7k5IaaXl/Lq1gMw7gLY8WpQE//GZHh4AVgIbloKf/1TuPn3UDISfnodvP54X4UoItJnkqmhzwY2uvsmd28CFgMLOlnvK8A9QGMK4+vWrPFDeGNHPUdPvwxizbDjLzDhXfDBb8Etf4SKYNx0Rp4Nn3gWhk2CP/93X4YoItInkknoY4DE4Qyr42VtzGwWMNbdnzjRjszsZjOrMrOqmprU3Nl57rghNEVjvJ5zNvzTbvjs6/CR70PlxyC3sP3KObkw8zrY/jLs25iS44uI9BenfFHUzELAN4G/725dd3/A3SvdvbKsrOxUDw0ENXQgaHaJFHS/wfRFYGFY+WhKji8i0l8kk9B3AGMT5svjZa1KgLOB35vZFmAOsKSvLowOL86jYlhhkNCTUTISJl4Kr/0EYnrAtIhkj2QS+nJgkplNMLNcYCGwpHWhu9e5+3B3r3D3CuBl4Ap3r+qViDtx7vihrNh2AHdPboOZ18HBXfDWs70bmIhIH+o2obt7C3AbsAxYCzzm7qvN7C4zu6K3A0zGueOHsO9QE9vebkhugzPmQ8FQ+MuPejcwEZE+lJPMSu6+FFjaoezOLta9+NTD6plzE9rRxw8r6n6DnFyYdg1UPQgNb0Ph0F6O8CREW2DXSmg5CrlFkFsMQ8ZDOJLuyESkn0oqofd3k04rpiQvh6qtB/jwrPLkNpr5UXjlv4KLoxf+be8GCFC/C6p+AOFcKBgCOXmwZzXs/AvUrIehE4Kbo8rOgh1VsGEZNNa230deKUx8L5w5HyZdFuxHRCQuKxJ6KGTMHD+EFcleGAUYeQ6cfgm88PWg50vR8N4L8PA+ePgK2PcmkNDOHymEUdNhygJ4e1Nww9PR+qA56Mz5MOl9QdJuPhKUb/lDkOhX/yLoqVPxTpj8QThzHgwe13vxi0hGyIqEDkF/9G8/s4H6xmYG5SfZLDH/nmB4gGe+DFd8p3cCa6yDR66C2m1w0xMwdjYcORCMMzN4HITCx9aNxaB+Bwwa3b681fSFwTo7V8C6J2Ddb+DJzwWvsrPgjPfBGfNg7Pmdby8iWS2jB+dKdP7pQ3GHFzfsS36jsjNhzq2w4hGofjX1QTU1wI+vhb1r4NofBXethiNQfFrQxNIx6YZCMHjsiZNxKATllXDpF+G25XBbFbzvX4NfGC/dDz+cD/dOgl/eCmuWaKRJkQHEku7ql2KVlZVeVZW6no3RmHPBvz3DzHGD+d71PegC31gP/3FeUCu+4X9h49NBs8awSUHbeiT/5AJyh5/dGCTVqx+Esz98cvvpica6oCvmuqXw5rJgPpQTjHNz5gdg2rVQNKz34xCRXmNmr7p7p0kuaxI6wJd/vZpHX9lG1T9fmnyzC8BrP4Vf3hy0S3sU8gcHFySHTQzGhJnw7p4H8+I3g6acy+6CuZ/p+fanKtocjA+/8WnY8FvYuxpCETjrgzDrRphwUVDbF5GMMmAS+optB/jwf/6Je/9qOlefm2RvFwhq00/FRwWesiBog970e3jidjiwBc77JMz7KoSTvOTw5tPw6F8FtfKP/ADMenoqqbdnDax4GFYtDtrwB4+HWdfDjOuCXycikhEGTEJ3d971ted4R1kxD31s9qnvsPkIPPMVePl+mPT+oOkkr7izAwfNG/s3Qs06eOofYcg4+Nhvjx8gLN2aG4OLqSsegs0vBEMMv+M9QU+fyZcnNx6OiKTNiRJ61vRyATAzPjR9NA+8sIn9h44yrDjv1HYYKYB5/w+GT4Qn/h7+53K46B+CRLjxd7D/Ldp1Q2xVMgqufbT/JXMIrgmcc3XwensTrPwxvLYYfv5xyC0JespMvhwmXgb5g9IdrYj0QFbV0AHW7qpn/r+/yFeuPJvr54xP3Y7XPwWP/w00N0BOftAHfNSMeI8UC+7mHDYRhk+CIRWZdUdnLAZbXoTXfwYbnoLDNUF7+/gLgr7wEy8LegT1h6YjkQFuwDS5QNDsctm3XmBoUS6P/Z8LUrvz/W9B7dag10i2Nk3EolC9POjnvvF3QZdLgEFj4PSLg5uxJrwbSkakNUyRgWrANLlA0OxyxfTRfOt3G9hVd4RRpSlMvMPeEbyyWSgM4+YEr/d9BWq3B4l903NBkm8dR374mcGTocbPDb7gBo1Kb9wikn01dICt+w9z0dd/z99dOom/u/SMXjnGgBSLBgOGbX4xaKLZ+hI0Hw6WDamA8vNg9CwYMwtGTuuf1xBEMtyAanJpdcODf2bdrnr+eMd7iITV37pXRJth96ogsW97CXasgIM7g2UWguFnBNcZRp5z7NUfR7YUySADqsml1Q1zxvOJh6v47eo9XD5NzQG9IhyBMecGrwtvC8oO7g4S+67Xgtfm54O+762KR8Jpk6FscpDwh00MXoNG66KryCnK2oR+yeTTGDO4gIdf2qKE3pdKRsLkDwSvVof3we7Xg9fetUFf/RWPHGuugaDnUGk5lI6Nv5cHF2JLx0DJ6GC/+aVK+iInkLUJPRwyPjpnPPc8tY71uw9y5siSdIc0cBUNh3dcErxaxWLBYwD3vxnckPX2ZqjbHlyE3bMaDu89fj+RwqCP/6DRwXvBECgYHAzVUDgsOE7hMMgrCbqRRgqD3kh90YXUPbjGkOzdxCK9IKv/9V173li+9bsNPPLyFv71ynPSHY4kCoWC2ndpvDtkRy1HoX5n8Dq4K3jV7wra6Ot3wfZXgvF2Guvp9OauRBYOfgHkFh17+lM4ErTzWyh46EgkP1gnnBsvN/BYEEe0CVoag7tsWxqDspbGDuVH2h8rJy84RigSJPnWY1koGDCt3SscvIdzg20j+RDOC56s1RpTTl5QFo7EX7nHtg9Hjp9OPJ5Z8I51+IWTMO8enG/r39I9mI5Fg5dH4+sn7rN1v8mwY9u1Hber94RtOk62fdQej7FdYULstF/Wej6J0+3eab+Nx9ovb5uOHftbdXxB+/lYNGE+euxL32NB19+RZyf5t0teVif0oUW5fHDaKH65YgefnzeZkp4M2CXplZMXDDE8dMKJ14tFg2EXGvYHTTsN+4Kx5psOBzeBtSbh5iNBE0/TYTh6CGItx/6jRZuD8W2aGyHWnPAf1OKJNJ5QIwXBRd3W5JqTd6w8Uhgk0tZk33wkOEasJdh/azKIRduXe/RY0myuDbZvPnLsy6KlCaJHg/Luvrgkc1z+TSX0k3HDBRX8YsUOfrFiBzdeWJHucCTVQuEgyRYODe7SzVbu8S+BpuCLINoc/2KIv0db2s+31Qaj7WuXiftLrLEeV3smmG79BdFaE3c/ts/WL75krmsk1myPqx17PJSEL6zOatlt4sdrjTeh6Lh12tbj+HPr+Oug3eaJf48Of5u2Xyjh9r+AWn8FhRJ/HYWPTYcSpiO906U36xP6jLGDmV5eyiMvb+WGC8ZjuqgmmcjsWHOLSBeSagAzs3lmtt7MNprZHZ0sv8XMXjezlWb2BzObkvpQT971F1Swce8hXnprf7pDERHpNd0mdDMLA/cD84EpwKJOEvaP3f0cd58BfA34ZqoDPRUfnDaKIYURHn5pa7pDERHpNcnU0GcDG919k7s3AYuBBYkruHvigyuL6GdXb/IjYa45byxPr93Dztoj6Q5HRKRXJJPQxwDbE+ar42XtmNmnzOwtghr6pzvbkZndbGZVZlZVU1NzMvGetI+eP56YOz9+ZVufHldEpK+kbJATd7/f3d8BfB745y7WecDdK929sqysLFWHTsrYoYW8d/JpLF6+jaMt0T49tohIX0gmoe8AxibMl8fLurIYuPIUYuo1119Qwb5DTSxbvSfdoYiIpFwyCX05MMnMJphZLrAQWJK4gpkldgC+HHgzdSGmzrsmDmfkoHx+/drOdIciIpJy3fZDd/cWM7sNWAaEgQfdfbWZ3QVUufsS4DYzuxRoBg4AN/Zm0CcrFDLmnzOSR1/ZxsHGZt05KiJZJakbi9x9KbC0Q9mdCdOfSXFcvebyc0bxwz9u4Zm1e7ly5nHXdkVEMtaAe/LDrHFDGDkonyde35XuUEREUmrAJfRQyJh39kie31DDwcbmdIcjIpIyAy6hQ3DnaFNLjGfXdTLmtohIhhqQCb212eU3q9TsIiLZY0AmdDW7iEg2GpAJHeDyeLPLM2vV7CIi2WHAJvRzxw1hdGk+v1p5opteRUQyx4BN6KGQceXMMbywoYa9BxvTHY6IyCkbsAkd4MOzxhBzWLJSQwGISOYb0Al94mklTC8v5ecr1OwiIplvQCd0gI+cW87aXfWs2Vnf/coiIv3YgE/oH5w2mkjY+MWK6nSHIiJySgZ8Qh9alMslZ57Gr1bupCUaS3c4IiInbcAndIAPzypn36GjvLhxX7pDERE5aUrowCWTyxhcGOHnr6rZRUQylxI6kJcT5orpo/ntmj3UHdFQACKSmZTQ4z48q5ymlhhPapx0EclQSuhx08tLeUdZET9XbxcRyVBK6HFmxodnlbN8ywG27j+c7nBERHpMCT3BVTPHYAa//IvuHBWRzKOEnmD04AIufMcwfrFiB+6e7nBERHokqYRuZvPMbL2ZbTSzOzpZfruZrTGzVWb2jJmNT32ofeMjs8rZ9nYDVVsPpDsUEZEe6Tahm1kYuB+YD0wBFpnZlA6r/QWodPdpwOPA11IdaF95/9SRFOaG+VnV9nSHIiLSI8nU0GcDG919k7s3AYuBBYkruPtz7t4Qn30ZKE9tmH2nKC+HBTNGs+S1ndQ2NKU7HBGRpCWT0McAidXV6nhZVz4OPNnZAjO72cyqzKyqpqYm+Sj72PVzKmhsjvGzKnVhFJHMkdKLomb2UaAS+Hpny939AXevdPfKsrKyVB46paaMHsTsiqE88vJWojFdHBWRzJBMQt8BjE2YL4+XtWNmlwL/BFzh7kdTE1763HDheLa93cDzG/QQaRHJDMkk9OXAJDObYGa5wEJgSeIKZjYT+B5BMs+KDPj+qSM5rSSPh/60Nd2hiIgkpduE7u4twG3AMmAt8Ji7rzazu8zsivhqXweKgZ+Z2UozW9LF7jJGJBziuvPH8/yGGjbv052jItL/JdWG7u5L3f0Md3+Hu98dL7vT3ZfEpy919xHuPiP+uuLEe8wMi84fSyRsPPzSlnSHIiLSLd0pegKnleTzgXNG8XhVNYeOtqQ7HBGRE1JC78ZNF1Zw8GgLj+tGIxHp55TQuzFz3BBmjB3MQy9tJaYujCLSjymhJ+Fv5lawed9hfq8ujCLSjymhJ+ED54xixKA8fvjHLekORUSkS0roSYiEQ1w/ZzwvvrmPN/ccTHc4IiKdUkJP0qLZ48jNCfGgauki0k8poSdpWHEeV59bzuOvbmf72w3dbyAi0seU0Hvg0++ZRMiMbz69Id2hiIgcRwm9B0aW5nPT3Ap+tXIHa3fVpzscEZF2lNB76P9eNJGSvBy+vmx9ukMREWlHCb2HSgsj3HrxRJ5dt5c/b3473eGIiLRRQj8JN11YwYhBeXz1ybW46+5REekflNBPQkFumNsvO4MV22p56o3d6Q5HRARQQj9pV587ljNHlHDPU+toaomlOxwRESX0kxUOGXd8YDJb9jfw6Ct6qpGIpJ8S+im4+Iwy5k4cxn3PvEndkeZ0hyMiA5wS+ikwM74w/yxqjzTz3d+/le5wRGSAU0I/RWePKeWqmWN48A+bNXCXiKSVEnoK/OMHzqIoL8znHl9FVA/BEJE0UUJPgeHFeXzpiqms3F7LD/6wKd3hiMgAlVRCN7N5ZrbezDaa2R2dLH+3ma0wsxYzuzr1YfZ/V0wfzWVTRvCN325gU82hdIcjIgNQtwndzMLA/cB8YAqwyMymdFhtG3AT8ONUB5gpzIy7rzybvJwQn3t8FS1R9U0Xkb6VTA19NrDR3Te5exOwGFiQuIK7b3H3VcCAzmKnDcrnrgVn8+rWA3xDQ+yKSB9LJqGPAbYnzFfHy3rMzG42syozq6qpqTmZXfR7V84cw6LZY/nu79/i6TV70h2OiAwgfXpR1N0fcPdKd68sKyvry0P3qS9+aCpnjxnE7Y+tZOv+w+kOR0QGiGQS+g5gbMJ8ebxMupAfCfPd684lZMatP1rBkaZoukMSkQEgmYS+HJhkZhPMLBdYCCzp3bAy39ihhXzr2ums3V3PF36xSsPsikiv6zahu3sLcBuwDFgLPObuq83sLjO7AsDMzjOzauCvgO+Z2ereDDpTvGfyCG6/9Ax+tXInP/jD5nSHIyJZLieZldx9KbC0Q9mdCdPLCZpipINPXTKRN3bW8W9PruOsUYOYO3F4ukMSkSylO0V7WShkfOOaGZw+vIhP/XgFb+yoS3dIIpKllND7QHFeDv99QyWFkTDXfO8lnlu/N90hiUgWUkLvIxXDi/jlp+ZSMayITzxUxY9f2ZbukEQkyyih96ERg/J57JYLeNek4fzjL1/n2u+9xJ827lMPGBFJCSX0Placl8P3b6jkix+awpb9h/nr77/C1f/1Ek+v2UNMQ++KyCmwdNUOKysrvaqqKi3H7i8am6P8rGo7//X8JnbUHmHC8CI+9s4JfGTWGApzk+qAJCIDjJm96u6VnS5TQk+/lmiMpW/s5vsvbmJVdR2D8nNYOHsc188Zz9ihhekOT0T6ESX0DOHuLN9ygIf+tIWnVu/G3bn4zNNYNHscl5xZRk5YLWQiA92JErp+1/cjZsbsCUOZPWEou+qO8OjL23isajuffLiKEYPyWDBjDO+fOpKZYwcTClm6wxWRfkY19H6uORrj2XV7+eny7bz4Zg3NUWfEoDzmnD6MySMHMXlUCZNHljByUD5mSvIi2U419AwWCYd4/9SRvH/qSOqONPPcur0sW72bqi0H+N+VO9vWKy2IcOaIEs4cWcIZI4o5Y0QJZ4woYUhRbhqjF5G+pISeQUoLIlw5cwxXzgyeL1J3pJl1u+pZv+cg63YfZP3ug/zqLzs4eLSlbZthRblMPK2Y08uKGT+skHFDCxkzuIChRbkMLcqlMDesmr1IllBCz2ClBRHOP30Y558+rK3M3dld38j63QfZuPcQb+45xMaaQzz1xi4ONDQft4/ccIjBhRGGFOYypKj1PZch8bLBhcH04MIIgwtzGVwQobQgogu0Iv2QEnqWMTNGlRYwqrSAi888rd2y+sZmtr/dwM7aRg40NHHgcBNvNzRRe7g5mG9o4s29h6htaOJAQzPRE9zoNCg/py3Zl7Ym/YJgujXpDy489j4oXpaXE+7tP4HIgKWEPoAMyo8wdXQpU0eXdrtuLOYcPNrSltxrG5qoO9LMgcNN1B5pprYh+BKojS/bsu8wdUeaqW9s5kTX2fMjIUrjyb31NSg/SPiDCiIMys+Jv0cYVJATvOdHKMnPoSQ/R78MRE5ACV06FQpZW8IdP6z79VtFY079kWbq4q/ahOm6+JdC66v+SAs7axtZ13iQuiPNHGxs6Xb/hblhSvKDRF+cn0NJa7LPy4kn/QjFeTkU5+cwKD+H4rxgveL48uK8HF03kKylhC4pFQ5Z0AZ/Er1rojHn0NEW6uM1/fojLdQ3Bom+Pp7wDzY2t5UdbGyhrqGJ6rcbOHg0WNbYHOv2OCGDotwciuKJvygvh+K8MMV5rdMJ77nhdmVFecF86/aFuWHyckL6gpB+QQld+o1wwq+Ck9UcjXH4aEtbwj90tIVDR5uPTbeVtXD4aOt0lMNHW9h3sCEobwrWa0lysLRwyCjMDVOUm0NBbpj8SJj8SIjccIjcnBCRcIickBHJCcoiYSMSDsVfwXROOEQkZMF72AiZEQ4ZoZARNiMc4liZHSsPWfBrKtRhnbAZ1jrdcdu26YRtzQiFOH5bMyxE/FjxdeLLDTBDX2b9iBK6ZJVIOBT0xik8tf737s7RlhgNTdG2xN/QdCz5Hz7aQkNTlENHWzjSFOVwUwsNR6McaY7S0BSlsTna9uXSFI3REnWaojGa49PN0RhHW4LplliM5mhmj7RpFnxpJCb5tmmCL4/WMoz4Mmvb1tr2YwnTwcrWtn68nM63S4wl8Tvm2B47lifG3/5Lybqc6bY4qS+4z7x3Eh+aPrrb9XpKCV2kE2YWr2mHGdoHN2e5Oy0xD5J9LEYs5kRjTtSdWAxiHswnvsecY9MxiCYuS9g22jrftp0Tje+z3XzrNu3WTzw2bcsc2mLAj8270zZNfNrj6wVF3u6iuce3DaaD5cemia97bJu298SyDuUk7r/D37jz8g6fRRfbdLVOcgvaO5VfoSeihC7SD5hZvPkFClDXTjk5SfUBM7N5ZrbezDaa2R2dLM8zs5/Gl79iZhUpj1RERE6o24RuZmHgfmA+MAVYZGZTOqz2ceCAu08EvgXck+pARUTkxJKpoc8GNrr7JndvAhYDCzqsswB4KD79OPBe06VvEZE+lUxCHwNsT5ivjpd1uo67twB1wHG3o5jZzWZWZWZVNTU1JxexiIh0qk/vo3b3B9y90t0ry8rK+vLQIiJZL5mEvgMYmzBfHi/rdB0zywFKgf2pCFBERJKTTEJfDkwyswlmlgssBJZ0WGcJcGN8+mrgWU/Xo5BERAaobvuhu3uLmd0GLAPCwIPuvtrM7gKq3H0J8APgETPbCLxNkPRFRKQPpe2ZomZWA2w9yc2HA/tSGE6mGIjnPRDPGQbmeQ/Ec4aen/d4d+/0ImTaEvqpMLOqrh6Sms0G4nkPxHOGgXneA/GcIbXnracFiIhkCSV0EZEskakJ/YF0B5AmA/G8B+I5w8A874F4zpDC887INnQRETleptbQRUSkAyV0EZEskXEJvbux2bOBmY01s+fMbI2ZrTazz8TLh5rZ02b2Zvx9SLpjTTUzC5vZX8zsN/H5CfEx9jfGx9zv/ccH9TEzG2xmj5vZOjNba2YXDJDP+rPxf99vmNlPzCw/2z5vM3vQzPaa2RsJZZ1+tha4L37uq8xsVk+Pl1EJPcmx2bNBC/D37j4FmAN8Kn6edwDPuPsk4Jn4fLb5DLA2Yf4e4FvxsfYPEIy9n23+HXjK3ScD0wnOP6s/azMbA3waqHT3swnuQl9I9n3e/wPM61DW1Wc7H5gUf90MfLenB8uohE5yY7NnPHff5e4r4tMHCf6Dj6H9uPMPAVemJcBeYmblwOXA9+PzBryHYIx9yM5zLgXeTTB8Bu7e5O61ZPlnHZcDFMQH9CsEdpFln7e7v0AwHEqirj7bBcDDHngZGGxmo3pyvExL6MmMzZ5V4o/zmwm8Aoxw913xRbuBEemKq5d8G/gHIBafHwbUxsfYh+z8vCcANcAP401N3zezIrL8s3b3HcC9wDaCRF4HvEr2f97Q9Wd7yvkt0xL6gGJmxcDPgb9z9/rEZfHRLLOmz6mZfRDY6+6vpjuWPpYDzAK+6+4zgcN0aF7Jts8aIN5uvIDgC200UMTxTRNZL9WfbaYl9GTGZs8KZhYhSOaPuvsv4sV7Wn+Cxd/3piu+XjAXuMLMthA0pb2HoG15cPwnOWTn510NVLv7K/H5xwkSfDZ/1gCXApvdvcbdm4FfEPwbyPbPG7r+bE85v2VaQk9mbPaMF287/gGw1t2/mbAocdz5G4H/7evYeou7f8Hdy929guBzfdbdrwOeIxhjH7LsnAHcfTew3czOjBe9F1hDFn/WcduAOWZWGP/33nreWf15x3X12S4Bboj3dpkD1CU0zSTH3TPqBXwA2AC8BfxTuuPppXN8J8HPsFXAyvjrAwRtys8AbwK/A4amO9ZeOv+Lgd/Ep08H/gxsBH4G5KU7vl443xlAVfzz/hUwZCB81sCXgXXAG8AjQF62fd7ATwiuETQT/Br7eFefLWAEvfjeAl4n6AHUo+Pp1n8RkSyRaU0uIiLSBSV0EZEsoYQuIpIllNBFRLKEErqISJZQQpesZWZRM1uZ8ErZAFdmVpE4gp5If5DT/SoiGeuIu89IdxAifUU1dBlwzGyLmX3NzF43sz+b2cR4eYWZPRsfi/oZMxsXLx9hZr80s9firwvjuwqb2X/Hx/T+rZkVpO2kRFBCl+xW0KHJ5dqEZXXufg7wHwSjPAJ8B3jI3acBjwL3xcvvA5539+kE46ysjpdPAu5396lALfCRXj0bkW7oTlHJWmZ2yN2LOynfArzH3TfFB0Hb7e7DzGwfMMrdm+Plu9x9uJnVAOXufjRhHxXA0x48pAAz+zwQcfd/7YNTE+mUaugyUHkX0z1xNGE6iq5JSZopoctAdW3C+0vx6T8RjPQIcB3wYnz6GeBWaHvmaWlfBSnSE6pRSDYrMLOVCfNPuXtr18UhZraKoJa9KF72twRPDvocwVOE/iZe/hngATP7OEFN/FaCEfRE+hW1ocuAE29Dr3T3femORSSV1OQiIpIlVEMXEckSqqGLiGQJJXQRkSyhhC4ikiWU0EVEsoQSuohIlvj/9PBm6xOtUQoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history_dense.history['loss'],label='Loss')\n",
    "plt.plot(history_dense.history['val_loss'],label='Val. loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Sets Classifier\n",
    "\n",
    "This model uses the `Conv1D` layer of Keras, but really it's more like the Deep Sets architecture applied to jets, the so-caled Particle-flow network approach{cite}`Komiske:2018cqr,NIPS2017_6931`.\n",
    "By using a kernel size of 1, we are applying the same fully connected neural network to each track. \n",
    "Then the `Lambda` layer sums over the tracks (actually it takes the mean). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 60, 48)            0         \n",
      "_________________________________________________________________\n",
      "bn_1 (BatchNormalization)    (None, 60, 48)            192       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 60, 64)            3136      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 60, 32)            2080      \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 60, 32)            1056      \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               3300      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 9,966\n",
      "Trainable params: 9,870\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, BatchNormalization, Conv1D, Flatten, Lambda\n",
    "import keras.backend as K\n",
    "\n",
    "# define Deep Sets model with Conv1D Keras layer\n",
    "inputs = Input(shape=(ntracks,nfeatures,), name = 'input')  \n",
    "x = BatchNormalization(name='bn_1')(inputs)\n",
    "x = Conv1D(64, 1, strides=1, padding='same', name = 'conv1d_1', activation='relu')(x)\n",
    "x = Conv1D(32, 1, strides=1, padding='same', name = 'conv1d_2', activation='relu')(x)\n",
    "x = Conv1D(32, 1, strides=1, padding='same', name = 'conv1d_3', activation='relu')(x)\n",
    "# sum over tracks\n",
    "x = Lambda(lambda x: K.mean(x, axis=-2), name = 'lambda_1', input_shape=(ntracks,32))(x)\n",
    "x = Dense(100, name = 'dense_1', activation='relu')(x)\n",
    "outputs = Dense(nlabels, name = 'output', activation='softmax')(x)\n",
    "keras_model_conv1d = Model(inputs=inputs, outputs=outputs)\n",
    "keras_model_conv1d.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(keras_model_conv1d.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv1d_1/convolution (defined at /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_13251]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fa62dc1f2b08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                         verbose=0)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m# reload best weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mkeras_model_conv1d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keras_model_conv1d_best.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m                 initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node conv1d_1/convolution (defined at /opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_13251]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "# define callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "reduce_lr = ReduceLROnPlateau(patience=5,factor=0.5)\n",
    "model_checkpoint = ModelCheckpoint('keras_model_conv1d_best.h5', monitor='val_loss', save_best_only=True)\n",
    "callbacks = [early_stopping, model_checkpoint, reduce_lr]\n",
    "\n",
    "# fit keras model\n",
    "history_conv1d = keras_model_conv1d.fit(train_generator, \n",
    "                                        validation_data = val_generator, \n",
    "                                        steps_per_epoch=len(train_generator), \n",
    "                                        validation_steps=len(val_generator),\n",
    "                                        max_queue_size=5,\n",
    "                                        epochs=100, \n",
    "                                        shuffle=False,\n",
    "                                        callbacks = callbacks, \n",
    "                                        verbose=0)\n",
    "# reload best weights\n",
    "keras_model_conv1d.load_weights('keras_model_conv1d_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history_conv1d.history['loss'],label='Loss')\n",
    "plt.plot(history_conv1d.history['val_loss'],label='Val. loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load testing file\n",
    "test_files = ['root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/test/ntuple_merged_0.root']\n",
    "test_generator = DataGenerator(test_files, features, labels, spectators, batch_size=1024, n_dim=ntracks, \n",
    "                               remove_mass_pt_window=True, \n",
    "                               remove_unlabeled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run model inference on test data set\n",
    "predict_array_dnn = []\n",
    "predict_array_cnn = []\n",
    "label_array_test = []\n",
    "\n",
    "for t in test_generator:\n",
    "    label_array_test.append(t[1])\n",
    "    predict_array_dnn.append(keras_model_dense.predict(t[0]))\n",
    "    predict_array_cnn.append(keras_model_conv1d.predict(t[0]))\n",
    "    \n",
    "    \n",
    "predict_array_dnn = np.concatenate(predict_array_dnn,axis=0)\n",
    "predict_array_cnn = np.concatenate(predict_array_cnn,axis=0)\n",
    "label_array_test = np.concatenate(label_array_test,axis=0)\n",
    "\n",
    "\n",
    "# create ROC curves\n",
    "fpr_dnn, tpr_dnn, threshold_dnn = roc_curve(label_array_test[:,1], predict_array_dnn[:,1])\n",
    "fpr_cnn, tpr_cnn, threshold_cnn = roc_curve(label_array_test[:,1], predict_array_cnn[:,1])\n",
    "    \n",
    "# plot ROC curves\n",
    "plt.figure()\n",
    "plt.plot(tpr_dnn, fpr_dnn, lw=2.5, label=\"Dense, AUC = {:.1f}%\".format(auc(fpr_dnn,tpr_dnn)*100))\n",
    "plt.plot(tpr_cnn, fpr_cnn, lw=2.5, label=\"Conv1D, AUC = {:.1f}%\".format(auc(fpr_cnn,tpr_cnn)*100))\n",
    "plt.xlabel(r'True positive rate')\n",
    "plt.ylabel(r'False positive rate')\n",
    "plt.semilogy()\n",
    "plt.ylim(0.001,1)\n",
    "plt.xlim(0,1)\n",
    "plt.grid(True)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the more structurally-aware Conv1D/Deep Sets model does better than a simple fully conneted neural network appraoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
