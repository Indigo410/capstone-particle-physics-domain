{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 7 Notebook: Optimizing Other Objectives\n",
    "===============================================================\n",
    "\n",
    "This week, we will look at optimizing multiple objectives simultaneously. In particular, we will look at pivoting with adversarial neural networks {cite}`Louppe:2016ylz,ganin2014unsupervised,Sirunyan:2019nfw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import uproot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 48 track-level features\n",
    "features = ['track_pt',\n",
    "            'track_ptrel',\n",
    "            'trackBTag_Eta',\n",
    "            'trackBTag_DeltaR',\n",
    "            'trackBTag_EtaRel',\n",
    "            'trackBTag_JetDistVal',\n",
    "            'trackBTag_Momentum',\n",
    "            'trackBTag_PPar',\n",
    "            'trackBTag_PParRatio',\n",
    "            'trackBTag_PtRatio',\n",
    "            'trackBTag_PtRel',\n",
    "            'trackBTag_Sip2dSig',\n",
    "            'trackBTag_Sip2dVal',\n",
    "            'trackBTag_Sip3dSig',\n",
    "            'trackBTag_Sip3dVal',\n",
    "            'track_VTX_ass',\n",
    "            'track_charge',\n",
    "            'track_deltaR',\n",
    "            'track_detadeta',\n",
    "            'track_dlambdadz',\n",
    "            'track_dlambdadz',\n",
    "            'track_dphidphi',\n",
    "            'track_dphidxy',\n",
    "            'track_dptdpt',\n",
    "            'track_drminsv',\n",
    "            'track_drsubjet1',\n",
    "            'track_drsubjet2',\n",
    "            'track_dxy',\n",
    "            'track_dxydxy',\n",
    "            'track_dxydz',\n",
    "            'track_dxysig',\n",
    "            'track_dz',\n",
    "            'track_dzdz',        \n",
    "            'track_dzsig',\n",
    "            'track_erel',\n",
    "            'track_etarel',\n",
    "            'track_fromPV',\n",
    "            'track_isChargedHad',\n",
    "            'track_isEl',\n",
    "            'track_isMu',\n",
    "            'track_lostInnerHits',\n",
    "            'track_mass',\n",
    "            'track_normchi2',            \n",
    "            'track_phirel',\n",
    "            'track_pt',\n",
    "            'track_ptrel',\n",
    "            'track_puppiw',\n",
    "            'track_quality']\n",
    "\n",
    "# spectators to define mass/pT window\n",
    "spectators = ['fj_sdmass',\n",
    "              'fj_pt']\n",
    "\n",
    "# 2 labels: QCD or Hbb (we'll reduce the following labels)\n",
    "labels =  ['label_QCD_b',\n",
    "           'label_QCD_bb',\n",
    "           'label_QCD_c', \n",
    "           'label_QCD_cc', \n",
    "           'label_QCD_others',\n",
    "           'sample_isQCD',\n",
    "           'label_H_bb']\n",
    "\n",
    "nfeatures = len(features)\n",
    "nspectators = len(spectators)\n",
    "nlabels = 2\n",
    "\n",
    "# we're going to zero-pad up to 60 tracks\n",
    "ntracks = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_files, features, labels, spectators, batch_size=1024, n_dim=60, \n",
    "                 remove_mass_pt_window=False, remove_unlabeled=True, return_spectators=False,\n",
    "                 max_entry = 20000):\n",
    "        'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_files = list_files\n",
    "        self.features = features\n",
    "        self.spectators = spectators\n",
    "        self.return_spectators = return_spectators\n",
    "        self.n_dim = n_dim\n",
    "        self.n_channels = len(features)\n",
    "        self.remove_mass_pt_window = remove_mass_pt_window\n",
    "        self.remove_unlabeled = remove_unlabeled\n",
    "        self.global_IDs = []\n",
    "        self.local_IDs = []\n",
    "        self.file_mapping = []\n",
    "        self.max_entry = max_entry\n",
    "        self.open_files = [None]*len(self.list_files)\n",
    "        running_total = 0\n",
    "        for i, file_name in enumerate(self.list_files):\n",
    "            root_file = uproot.open(file_name)\n",
    "            self.open_files.append(root_file)\n",
    "            tree = root_file['deepntuplizer/tree']\n",
    "            tree_length = min(len(tree),max_entry)\n",
    "            self.global_IDs.append(np.arange(running_total,running_total+tree_length))\n",
    "            self.local_IDs.append(np.arange(tree_length))\n",
    "            self.file_mapping.append(np.repeat(i,tree_length))\n",
    "            running_total += tree_length\n",
    "            root_file.close()\n",
    "        self.global_IDs = np.concatenate(self.global_IDs)\n",
    "        self.local_IDs = np.concatenate(self.local_IDs)\n",
    "        self.file_mapping = np.concatenate(self.file_mapping)\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.global_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        files = self.file_mapping[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        unique_files = np.unique(files)\n",
    "        starts = np.array([min(indexes[files==i]) for i in unique_files])\n",
    "        stops = np.array([max(indexes[files==i]) for i in unique_files])\n",
    "\n",
    "        # Check if files needed open (if not open them)\n",
    "        # Also if file is not needed, close it\n",
    "        for ifile, file_name in enumerate(self.list_files):\n",
    "            if ifile in unique_files:\n",
    "                if self.open_files[ifile] is None: \n",
    "                    self.open_files[ifile] = uproot.open(file_name)\n",
    "            else:\n",
    "                if self.open_files[ifile] is not None: \n",
    "                    self.open_files[ifile].close()\n",
    "                    self.open_files[ifile] = None\n",
    "            \n",
    "        # Generate data\n",
    "        return self.__data_generation(unique_files, starts, stops)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = self.local_IDs\n",
    "\n",
    "    def __data_generation(self, unique_files, starts, stops):\n",
    "        'Generates data containing batch_size samples' \n",
    "        # X : (n_samples, n_dim, n_channels)\n",
    "        # y : (n_samples, 2)\n",
    "        Xs = []\n",
    "        ys = []\n",
    "        zs = []\n",
    "        \n",
    "        # Generate data\n",
    "        for ifile, start, stop in zip(unique_files, starts, stops):\n",
    "            if self.return_spectators:\n",
    "                X, y, z = self.__get_features_labels(ifile, start, stop)\n",
    "                zs.append(z)\n",
    "            else:\n",
    "                X, y = self.__get_features_labels(ifile, start, stop)\n",
    "            Xs.append(X)\n",
    "            ys.append(y)\n",
    "            \n",
    "        # Stack data if going over multiple files\n",
    "        if len(unique_files)>1:\n",
    "            X = np.concatenate(Xs,axis=0)\n",
    "            y = np.concatenate(ys,axis=0)\n",
    "            if self.return_spectators:\n",
    "                z = np.concatenate(zs,axis=0)\n",
    "            \n",
    "        if self.return_spectators:\n",
    "            return X, [y, z]\n",
    "        \n",
    "        return X, y\n",
    "                         \n",
    "    def __get_features_labels(self, ifile, entrystart, entrystop):\n",
    "        'Loads data from one file'\n",
    "        \n",
    "        # Double check that file is open\n",
    "        if self.open_files[ifile] is None:\n",
    "            root_file = uproot.open(self.list_file[ifile])\n",
    "        else:\n",
    "            root_file = self.open_files[ifile]\n",
    "            \n",
    "        tree = root_file['deepntuplizer/tree']\n",
    "        \n",
    "        feature_array = tree.arrays(branches=self.features, \n",
    "                                    entrystart=entrystart,\n",
    "                                    entrystop=entrystop,\n",
    "                                    namedecode='utf-8')\n",
    "\n",
    "        label_array_all = tree.arrays(branches=self.labels, \n",
    "                                      entrystart=entrystart,\n",
    "                                      entrystop=entrystop,\n",
    "                                      namedecode='utf-8')\n",
    "\n",
    "        X = np.stack([feature_array[feat].pad(self.n_dim, clip=True).fillna(0).regular() for feat in features],axis=2)\n",
    "        n_samples = X.shape[0]\n",
    "    \n",
    "        y = np.zeros((n_samples,2))\n",
    "        y[:,0] = label_array_all['sample_isQCD'] * (label_array_all['label_QCD_b'] + \\\n",
    "                                                    label_array_all['label_QCD_bb'] + \\\n",
    "                                                    label_array_all['label_QCD_c'] + \\\n",
    "                                                    label_array_all['label_QCD_cc'] + \\\n",
    "                                                    label_array_all['label_QCD_others'])\n",
    "        y[:,1] = label_array_all['label_H_bb']\n",
    "\n",
    "        \n",
    "        if self.remove_mass_pt_window:\n",
    "            # remove data outside of mass/pT range\n",
    "            spec_array = tree.arrays(branches=self.spectators, \n",
    "                                     entrystart=entrystart,\n",
    "                                     entrystop=entrystop,\n",
    "                                     namedecode='utf-8')\n",
    "            \n",
    "            z = np.stack([spec_array[spec] for spec in self.spectators],axis=1)\n",
    "            X = X[(z[:,0] > 40) & (z[:,0] < 200) & (z[:,1] > 300) & (z[:,1] < 2000)]\n",
    "            y = y[(z[:,0] > 40) & (z[:,0] < 200) & (z[:,1] > 300) & (z[:,1] < 2000)]\n",
    "            z = z[(z[:,0] > 40) & (z[:,0] < 200) & (z[:,1] > 300) & (z[:,1] < 2000)]\n",
    "                        \n",
    "        if self.remove_unlabeled:\n",
    "            # remove unlabeled data\n",
    "            X = X[np.sum(y,axis=1)==1]\n",
    "            if self.return_spectators:\n",
    "                z = z[np.sum(y,axis=1)==1]\n",
    "            y = y[np.sum(y,axis=1)==1]\n",
    "            \n",
    "        if self.return_spectators:\n",
    "            return X, [y, z]\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Gradient Reversal Layer\n",
    "Here, we define a gradient reversal layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.custom_gradient\n",
    "def grad_reverse(x):\n",
    "    y = tf.identity(x)\n",
    "    def custom_grad(dy):\n",
    "        return -dy\n",
    "    return y, custom_grad\n",
    "\n",
    "class GradReverse(keras.layers.Layer):\n",
    "    def __init__(self, name='GradReverse'):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, x):\n",
    "        return grad_reverse(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Combined Model with Adversarial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 60, 48)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_1 (BatchNormalization)       (None, 60, 48)       192         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 60, 64)       3136        bn_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 60, 32)       2080        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 60, 32)       1056        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 32)           0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          3300        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            202         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reverse_1 (GradReverse)         (None, 2)            0           output[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 100)          300         reverse_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          10100       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mass_reg (Dense)                (None, 2)            202         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat_2 (Concatenate)          (None, 4)            0           mass_reg[0][0]                   \n",
      "                                                                 output[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 20,568\n",
      "Trainable params: 20,472\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, BatchNormalization, Conv1D, Flatten, Lambda, Concatenate\n",
    "import keras.backend as K\n",
    "\n",
    "# define Deep Sets model with Conv1D Keras layer\n",
    "inputs = Input(shape=(ntracks,nfeatures,), name = 'input')  \n",
    "x = BatchNormalization(name='bn_1')(inputs)\n",
    "x = Conv1D(64, 1, strides=1, padding='same', name = 'conv1d_1', activation='relu')(x)\n",
    "x = Conv1D(32, 1, strides=1, padding='same', name = 'conv1d_2', activation='relu')(x)\n",
    "x = Conv1D(32, 1, strides=1, padding='same', name = 'conv1d_3', activation='relu')(x)\n",
    "# sum over tracks\n",
    "x = Lambda(lambda x: K.mean(x, axis=-2), name = 'lambda_1', input_shape=(ntracks,32))(x)\n",
    "x = Dense(100, name = 'dense_1', activation='relu')(x)\n",
    "output = Dense(nlabels, name = 'output', activation='softmax')(x)\n",
    " \n",
    "# start adversarial part\n",
    "x = GradReverse(name='reverse_1')(output)\n",
    "x = Dense(100, name='dense_2', activation ='relu')(x)\n",
    "x = Dense(100, name= 'dense_3',activation='relu')(x)\n",
    "output_reg = Dense(2, activation='linear', name='mass_reg')(x)\n",
    "outputs = Concatenate(name='concat_2')([output_reg, output])\n",
    "                                                            \n",
    "\n",
    "keras_model_adv = Model(inputs=inputs, outputs=outputs)\n",
    "keras_model_adv.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(keras_model_adv.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
