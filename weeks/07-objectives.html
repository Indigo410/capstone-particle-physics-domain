
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Week 7 Notebook: Optimizing Other Objectives &#8212; Particle Physics and Machine Learning</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.2d2078699c18a0efb88233928e1cf6ed.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Week 8: Extending the Model" href="08.html" />
    <link rel="prev" title="Week 7: Optimizing Other Objectives" href="07.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Particle Physics and Machine Learning</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../README.html">
   Particle Physics and Machine Learning
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="01.html">
   Week 1: Introduction to Particle Physics and Jets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02.html">
   Week 2: Data Formats and Exploration
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03.html">
   Week 3: Feature Engineering
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04.html">
   Week 4: Simple Classifiers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="05.html">
   Week 5: Building a Deep Learning Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06.html">
   Week 6: Evalulating Model Performance and Robustness
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="07.html">
   Week 7: Optimizing Other Objectives
  </a>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Week 7 Notebook: Optimizing Other Objectives
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08.html">
   Week 8: Extending the Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09.html">
   Week 9: Application to Real Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../zreferences.html">
   References
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/weeks/07-objectives.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/jmduarte/capstone-particle-physics-domain"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/jmduarte/capstone-particle-physics-domain/issues/new?title=Issue%20on%20page%20%2Fweeks/07-objectives.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/jmduarte/capstone-particle-physics-domain/edit/master/weeks/07-objectives.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/jmduarte/capstone-particle-physics-domain/master?urlpath=tree/weeks/07-objectives.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://datahub.ucsd.edu/hub/user-redirect/git-pull?repo=https://github.com/jmduarte/capstone-particle-physics-domain&urlpath=tree/capstone-particle-physics-domain/weeks/07-objectives.ipynb&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/jmduarte/capstone-particle-physics-domain/blob/master/weeks/07-objectives.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#define-discriminator-regressor-and-combined-adversarial-model">
   Define Discriminator, Regressor, and Combined Adversarial Model
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="week-7-notebook-optimizing-other-objectives">
<h1>Week 7 Notebook: Optimizing Other Objectives<a class="headerlink" href="#week-7-notebook-optimizing-other-objectives" title="Permalink to this headline">¶</a></h1>
<p>This week, we will look at optimizing multiple objectives simultaneously. In particular, we will look at pivoting with adversarial neural networks <a class="bibtex reference internal" href="../zreferences.html#louppe-2016ylz" id="id1">[17]</a><a class="bibtex reference internal" href="../zreferences.html#ganin2014unsupervised" id="id2">[18]</a><a class="bibtex reference internal" href="../zreferences.html#sirunyan-2019nfw" id="id3">[19]</a>.</p>
<p>We will borrow the implementation from: <a class="reference external" href="https://github.com/glouppe/paper-learning-to-pivot">https://github.com/glouppe/paper-learning-to-pivot</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">keras</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">uproot</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using TensorFlow backend.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># 48 track-level features</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;track_pt&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_ptrel&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_Eta&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_DeltaR&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_EtaRel&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_JetDistVal&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_Momentum&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_PPar&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_PParRatio&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_PtRatio&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_PtRel&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_Sip2dSig&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_Sip2dVal&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_Sip3dSig&#39;</span><span class="p">,</span>
            <span class="s1">&#39;trackBTag_Sip3dVal&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_VTX_ass&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_charge&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_deltaR&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_detadeta&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_dlambdadz&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_dlambdadz&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_dphidphi&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_dphidxy&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_dptdpt&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_drminsv&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_drsubjet1&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_drsubjet2&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_dxy&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_dxydxy&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_dxydz&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_dxysig&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_dz&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_dzdz&#39;</span><span class="p">,</span>        
            <span class="s1">&#39;track_dzsig&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_erel&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_etarel&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_fromPV&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_isChargedHad&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_isEl&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_isMu&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_lostInnerHits&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_mass&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_normchi2&#39;</span><span class="p">,</span>            
            <span class="s1">&#39;track_phirel&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_pt&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_ptrel&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_puppiw&#39;</span><span class="p">,</span>
            <span class="s1">&#39;track_quality&#39;</span><span class="p">]</span>

<span class="c1"># spectators to define mass/pT window</span>
<span class="n">spectators</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;fj_sdmass&#39;</span><span class="p">,</span>
              <span class="s1">&#39;fj_pt&#39;</span><span class="p">]</span>

<span class="c1"># 2 labels: QCD or Hbb (we&#39;ll reduce the following labels)</span>
<span class="n">labels</span> <span class="o">=</span>  <span class="p">[</span><span class="s1">&#39;label_QCD_b&#39;</span><span class="p">,</span>
           <span class="s1">&#39;label_QCD_bb&#39;</span><span class="p">,</span>
           <span class="s1">&#39;label_QCD_c&#39;</span><span class="p">,</span> 
           <span class="s1">&#39;label_QCD_cc&#39;</span><span class="p">,</span> 
           <span class="s1">&#39;label_QCD_others&#39;</span><span class="p">,</span>
           <span class="s1">&#39;sample_isQCD&#39;</span><span class="p">,</span>
           <span class="s1">&#39;label_H_bb&#39;</span><span class="p">]</span>

<span class="n">nfeatures</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="n">nspectators</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">spectators</span><span class="p">)</span>
<span class="n">nlabels</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># we&#39;re going to zero-pad up to 60 tracks</span>
<span class="n">ntracks</span> <span class="o">=</span> <span class="mi">60</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">DataGenerator</span> <span class="kn">import</span> <span class="n">DataGenerator</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="n">Traceback</span> <span class="p">(</span><span class="n">most</span> <span class="n">recent</span> <span class="n">call</span> <span class="n">last</span><span class="p">):</span>

  <span class="n">File</span> <span class="s2">&quot;/usr/share/miniconda/envs/analysis/lib/python3.7/site-packages/IPython/core/interactiveshell.py&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">3417</span><span class="p">,</span> <span class="ow">in</span> <span class="n">run_code</span>
    <span class="n">exec</span><span class="p">(</span><span class="n">code_obj</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_global_ns</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">user_ns</span><span class="p">)</span>

  <span class="n">File</span> <span class="s2">&quot;&lt;ipython-input-3-d4897d4e31d8&gt;&quot;</span><span class="p">,</span> <span class="n">line</span> <span class="mi">1</span><span class="p">,</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
    <span class="kn">from</span> <span class="nn">DataGenerator</span> <span class="kn">import</span> <span class="n">DataGenerator</span>

<span class="gt">  File</span><span class="nn"> &quot;/home/runner/work/capstone-particle-physics-domain/capstone-particle-physics-domain/weeks/DataGenerator.py&quot;</span><span class="gt">, line </span><span class="mi">139</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">remove_mass_pt_window</span><span class="p">:</span>
     <span class="o">^</span>
<span class="ne">IndentationError</span>: expected an indented block
</pre></div>
</div>
</div>
</div>
<div class="section" id="define-discriminator-regressor-and-combined-adversarial-model">
<h2>Define Discriminator, Regressor, and Combined Adversarial Model<a class="headerlink" href="#define-discriminator-regressor-and-combined-adversarial-model" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">BatchNormalization</span><span class="p">,</span> <span class="n">Conv1D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">Concatenate</span>
<span class="kn">import</span> <span class="nn">keras.backend</span> <span class="k">as</span> <span class="nn">K</span>

<span class="c1"># define Deep Sets model with Conv1D Keras layer</span>
<span class="n">inputs</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">ntracks</span><span class="p">,</span><span class="n">nfeatures</span><span class="p">,),</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;input&#39;</span><span class="p">)</span>  
<span class="n">x</span> <span class="o">=</span> <span class="n">BatchNormalization</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">&#39;bn_1&#39;</span><span class="p">)(</span><span class="n">inputs</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv1d_1&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv1d_2&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Conv1D</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">strides</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;conv1d_3&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="c1"># sum over tracks</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Lambda</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">K</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">2</span><span class="p">),</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;lambda_1&#39;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="n">ntracks</span><span class="p">,</span><span class="mi">32</span><span class="p">))(</span><span class="n">x</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;dense_1&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">nlabels</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;output&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
    
<span class="n">keras_model_disc</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">output</span><span class="p">)</span>
<span class="n">keras_model_disc</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
                        <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">)</span>

<span class="c1"># regressor</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;dense_2&#39;</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">keras_model_disc</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span> <span class="s1">&#39;dense_3&#39;</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
<span class="n">output_reg</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;mass_pt_reg&#39;</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
                                                            

<span class="n">sgd_opt</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">momentum</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">keras_model_reg</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">output_reg</span><span class="p">)</span>
<span class="n">keras_model_reg</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">sgd_opt</span><span class="p">,</span>
                        <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">)</span>

<span class="c1"># combined model</span>
<span class="n">lam</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="n">keras_model_adv</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="p">[</span><span class="n">keras_model_disc</span><span class="p">(</span><span class="n">inputs</span><span class="p">),</span> <span class="n">keras_model_reg</span><span class="p">(</span><span class="n">inputs</span><span class="p">)])</span>
<span class="n">keras_model_adv</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">sgd_opt</span><span class="p">,</span> 
                        <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="s1">&#39;mse&#39;</span><span class="p">],</span>
                        <span class="n">loss_weights</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="n">lam</span><span class="p">])</span>                              

<span class="nb">print</span><span class="p">(</span><span class="n">keras_model_disc</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">keras_model_reg</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">keras_model_adv</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model: &quot;model_1&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 60, 48)            0         
_________________________________________________________________
bn_1 (BatchNormalization)    (None, 60, 48)            192       
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 60, 64)            3136      
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 60, 32)            2080      
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 60, 32)            1056      
_________________________________________________________________
lambda_1 (Lambda)            (None, 32)                0         
_________________________________________________________________
dense_1 (Dense)              (None, 100)               3300      
_________________________________________________________________
output (Dense)               (None, 2)                 202       
=================================================================
Total params: 9,966
Trainable params: 9,870
Non-trainable params: 96
_________________________________________________________________
None
Model: &quot;model_2&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           (None, 60, 48)            0         
_________________________________________________________________
model_1 (Model)              (None, 2)                 9966      
_________________________________________________________________
dense_2 (Dense)              (None, 100)               300       
_________________________________________________________________
dense_3 (Dense)              (None, 100)               10100     
_________________________________________________________________
mass_pt_reg (Dense)          (None, 2)                 202       
=================================================================
Total params: 20,568
Trainable params: 20,472
Non-trainable params: 96
_________________________________________________________________
None
Model: &quot;model_3&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input (InputLayer)              (None, 60, 48)       0                                            
__________________________________________________________________________________________________
model_1 (Model)                 (None, 2)            9966        input[0][0]                      
__________________________________________________________________________________________________
model_2 (Model)                 (None, 2)            20568       input[0][0]                      
==================================================================================================
Total params: 20,568
Trainable params: 20,472
Non-trainable params: 96
__________________________________________________________________________________________________
None
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load training and validation generators </span>
<span class="n">train_files</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/train/ntuple_merged_10.root&#39;</span><span class="p">]</span>
<span class="n">val_files</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/train/ntuple_merged_11.root&#39;</span><span class="p">]</span>


<span class="n">train_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">train_files</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">spectators</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">n_dim</span><span class="o">=</span><span class="n">ntracks</span><span class="p">,</span> 
                                <span class="n">remove_mass_pt_window</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                <span class="n">remove_unlabeled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_entry</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span>
                                <span class="n">return_spectators</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale_mass_pt</span><span class="o">=</span><span class="p">[</span><span class="mf">100.</span><span class="p">,</span><span class="mf">10000.</span><span class="p">])</span>

<span class="n">val_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">val_files</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">spectators</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">n_dim</span><span class="o">=</span><span class="n">ntracks</span><span class="p">,</span> 
                              <span class="n">remove_mass_pt_window</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                              <span class="n">remove_unlabeled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_entry</span><span class="o">=</span><span class="mi">5000</span><span class="p">,</span> 
                              <span class="n">return_spectators</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale_mass_pt</span><span class="o">=</span><span class="p">[</span><span class="mf">100.</span><span class="p">,</span><span class="mf">10000.</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># pretrain discriminator</span>
<span class="n">keras_model_disc</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">keras_model_disc</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span>
                        <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">train_generator</span><span class="p">:</span>
        <span class="n">keras_model_disc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>        
        
<span class="c1"># pretrain regressor</span>
<span class="n">keras_model_reg</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">keras_model_disc</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">keras_model_reg</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">sgd_opt</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">train_generator</span><span class="p">:</span>
        <span class="n">keras_model_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>                 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/1
943/943 [==============================] - 2s 2ms/step - loss: 0.4702
Epoch 1/1
950/950 [==============================] - 0s 194us/step - loss: 0.3813
Epoch 1/1
967/967 [==============================] - 0s 181us/step - loss: 0.3747
Epoch 1/1
954/954 [==============================] - 0s 184us/step - loss: 0.3165
Epoch 1/1
943/943 [==============================] - 0s 142us/step - loss: 0.3251
Epoch 1/1
950/950 [==============================] - 0s 143us/step - loss: 0.2878
Epoch 1/1
967/967 [==============================] - 0s 145us/step - loss: 0.2784
Epoch 1/1
954/954 [==============================] - 0s 141us/step - loss: 0.2344
Epoch 1/1
943/943 [==============================] - 0s 146us/step - loss: 0.2325
Epoch 1/1
950/950 [==============================] - 0s 139us/step - loss: 0.2617
Epoch 1/1
967/967 [==============================] - 0s 143us/step - loss: 0.2409
Epoch 1/1
954/954 [==============================] - 0s 141us/step - loss: 0.2114
Epoch 1/1
943/943 [==============================] - 0s 136us/step - loss: 0.2138
Epoch 1/1
950/950 [==============================] - 0s 138us/step - loss: 0.2179
Epoch 1/1
967/967 [==============================] - 0s 151us/step - loss: 0.2141
Epoch 1/1
954/954 [==============================] - 0s 141us/step - loss: 0.1940
Epoch 1/1
943/943 [==============================] - 0s 143us/step - loss: 0.2039
Epoch 1/1
950/950 [==============================] - 0s 141us/step - loss: 0.2057
Epoch 1/1
967/967 [==============================] - 0s 144us/step - loss: 0.1932
Epoch 1/1
954/954 [==============================] - 0s 148us/step - loss: 0.1802
Epoch 1/1
943/943 [==============================] - 0s 142us/step - loss: 0.1800
Epoch 1/1
950/950 [==============================] - 0s 138us/step - loss: 0.1984
Epoch 1/1
967/967 [==============================] - 0s 138us/step - loss: 0.1791
Epoch 1/1
954/954 [==============================] - 0s 147us/step - loss: 0.1608
Epoch 1/1
943/943 [==============================] - 0s 153us/step - loss: 0.1617
Epoch 1/1
950/950 [==============================] - 0s 143us/step - loss: 0.1827
Epoch 1/1
967/967 [==============================] - 0s 142us/step - loss: 0.1691
Epoch 1/1
954/954 [==============================] - 0s 143us/step - loss: 0.1458
Epoch 1/1
943/943 [==============================] - 0s 142us/step - loss: 0.1556
Epoch 1/1
950/950 [==============================] - 0s 140us/step - loss: 0.1718
Epoch 1/1
967/967 [==============================] - 0s 152us/step - loss: 0.1521
Epoch 1/1
954/954 [==============================] - 0s 146us/step - loss: 0.1503
Epoch 1/1
943/943 [==============================] - 0s 139us/step - loss: 0.1466
Epoch 1/1
950/950 [==============================] - 0s 140us/step - loss: 0.1627
Epoch 1/1
967/967 [==============================] - 0s 150us/step - loss: 0.1402
Epoch 1/1
954/954 [==============================] - 0s 141us/step - loss: 0.1299
Epoch 1/1
943/943 [==============================] - 0s 156us/step - loss: 0.1281
Epoch 1/1
950/950 [==============================] - 0s 139us/step - loss: 0.1505
Epoch 1/1
967/967 [==============================] - 0s 140us/step - loss: 0.1353
Epoch 1/1
954/954 [==============================] - 0s 155us/step - loss: 0.1220
Epoch 1/1
943/943 [==============================] - 0s 148us/step - loss: 0.1165
Epoch 1/1
950/950 [==============================] - 0s 143us/step - loss: 0.1405
Epoch 1/1
967/967 [==============================] - 0s 148us/step - loss: 0.1290
Epoch 1/1
954/954 [==============================] - 0s 141us/step - loss: 0.1279
Epoch 1/1
943/943 [==============================] - 0s 147us/step - loss: 0.1317
Epoch 1/1
950/950 [==============================] - 0s 146us/step - loss: 0.1306
Epoch 1/1
967/967 [==============================] - 0s 143us/step - loss: 0.1287
Epoch 1/1
954/954 [==============================] - 0s 140us/step - loss: 0.1111
Epoch 1/1
943/943 [==============================] - 0s 139us/step - loss: 0.1062
Epoch 1/1
950/950 [==============================] - 0s 138us/step - loss: 0.1256
Epoch 1/1
967/967 [==============================] - 0s 139us/step - loss: 0.1199
Epoch 1/1
954/954 [==============================] - 0s 140us/step - loss: 0.1103
Epoch 1/1
943/943 [==============================] - 0s 137us/step - loss: 0.1239
Epoch 1/1
950/950 [==============================] - 0s 138us/step - loss: 0.1331
Epoch 1/1
967/967 [==============================] - 0s 140us/step - loss: 0.1071
Epoch 1/1
954/954 [==============================] - 0s 141us/step - loss: 0.1019
Epoch 1/1
943/943 [==============================] - 0s 143us/step - loss: 0.1045
Epoch 1/1
950/950 [==============================] - 0s 138us/step - loss: 0.1259
Epoch 1/1
967/967 [==============================] - 0s 151us/step - loss: 0.1100
Epoch 1/1
954/954 [==============================] - 0s 141us/step - loss: 0.1150
Epoch 1/1
943/943 [==============================] - 0s 138us/step - loss: 0.1169
Epoch 1/1
950/950 [==============================] - 0s 140us/step - loss: 0.1363
Epoch 1/1
967/967 [==============================] - 0s 141us/step - loss: 0.1072
Epoch 1/1
954/954 [==============================] - 0s 142us/step - loss: 0.1004
Epoch 1/1
943/943 [==============================] - 0s 159us/step - loss: 0.1036
Epoch 1/1
950/950 [==============================] - 0s 146us/step - loss: 0.1174
Epoch 1/1
967/967 [==============================] - 0s 143us/step - loss: 0.0973
Epoch 1/1
954/954 [==============================] - 0s 141us/step - loss: 0.0969
Epoch 1/1
943/943 [==============================] - 0s 143us/step - loss: 0.1029
Epoch 1/1
950/950 [==============================] - 0s 135us/step - loss: 0.1105
Epoch 1/1
967/967 [==============================] - 0s 139us/step - loss: 0.0970
Epoch 1/1
954/954 [==============================] - 0s 137us/step - loss: 0.1015
Epoch 1/1
943/943 [==============================] - 0s 142us/step - loss: 0.1090
Epoch 1/1
950/950 [==============================] - 0s 140us/step - loss: 0.1187
Epoch 1/1
967/967 [==============================] - 0s 139us/step - loss: 0.1002
Epoch 1/1
954/954 [==============================] - 0s 136us/step - loss: 0.1180
Epoch 1/1
943/943 [==============================] - 0s 140us/step - loss: 0.0978
Epoch 1/1
950/950 [==============================] - 0s 137us/step - loss: 0.1198
Epoch 1/1
967/967 [==============================] - 0s 146us/step - loss: 0.1021
Epoch 1/1
954/954 [==============================] - 0s 139us/step - loss: 0.0896
Epoch 1/1
943/943 [==============================] - 0s 220us/step - loss: 0.8344
Epoch 1/1
950/950 [==============================] - 0s 67us/step - loss: 0.4811
Epoch 1/1
967/967 [==============================] - 0s 73us/step - loss: 0.4680
Epoch 1/1
954/954 [==============================] - 0s 73us/step - loss: 0.7412
Epoch 1/1
943/943 [==============================] - 0s 68us/step - loss: 0.6820
Epoch 1/1
950/950 [==============================] - 0s 69us/step - loss: 0.4507
Epoch 1/1
967/967 [==============================] - 0s 70us/step - loss: 0.4549
Epoch 1/1
954/954 [==============================] - 0s 69us/step - loss: 0.7313
Epoch 1/1
943/943 [==============================] - 0s 67us/step - loss: 0.6733
Epoch 1/1
950/950 [==============================] - 0s 67us/step - loss: 0.4432
Epoch 1/1
967/967 [==============================] - 0s 70us/step - loss: 0.4496
Epoch 1/1
954/954 [==============================] - 0s 72us/step - loss: 0.7266
Epoch 1/1
943/943 [==============================] - 0s 69us/step - loss: 0.6684
Epoch 1/1
950/950 [==============================] - 0s 69us/step - loss: 0.4394
Epoch 1/1
967/967 [==============================] - 0s 75us/step - loss: 0.4475
Epoch 1/1
954/954 [==============================] - 0s 69us/step - loss: 0.7231
Epoch 1/1
943/943 [==============================] - 0s 70us/step - loss: 0.6658
Epoch 1/1
950/950 [==============================] - 0s 67us/step - loss: 0.4363
Epoch 1/1
967/967 [==============================] - 0s 74us/step - loss: 0.4454
Epoch 1/1
954/954 [==============================] - 0s 69us/step - loss: 0.7221
Epoch 1/1
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>943/943 [==============================] - 0s 69us/step - loss: 0.6654
Epoch 1/1
950/950 [==============================] - 0s 69us/step - loss: 0.4353
Epoch 1/1
967/967 [==============================] - 0s 70us/step - loss: 0.4442
Epoch 1/1
954/954 [==============================] - 0s 67us/step - loss: 0.7199
Epoch 1/1
943/943 [==============================] - 0s 68us/step - loss: 0.6636
Epoch 1/1
950/950 [==============================] - 0s 69us/step - loss: 0.4340
Epoch 1/1
967/967 [==============================] - 0s 68us/step - loss: 0.4440
Epoch 1/1
954/954 [==============================] - 0s 68us/step - loss: 0.7200
Epoch 1/1
943/943 [==============================] - 0s 69us/step - loss: 0.6618
Epoch 1/1
950/950 [==============================] - 0s 72us/step - loss: 0.4333
Epoch 1/1
967/967 [==============================] - 0s 69us/step - loss: 0.4416
Epoch 1/1
954/954 [==============================] - 0s 69us/step - loss: 0.7201
Epoch 1/1
943/943 [==============================] - 0s 68us/step - loss: 0.6619
Epoch 1/1
950/950 [==============================] - 0s 68us/step - loss: 0.4313
Epoch 1/1
967/967 [==============================] - 0s 69us/step - loss: 0.4429
Epoch 1/1
954/954 [==============================] - 0s 72us/step - loss: 0.7203
Epoch 1/1
943/943 [==============================] - 0s 70us/step - loss: 0.6630
Epoch 1/1
950/950 [==============================] - 0s 68us/step - loss: 0.4323
Epoch 1/1
967/967 [==============================] - 0s 68us/step - loss: 0.4424
Epoch 1/1
954/954 [==============================] - 0s 67us/step - loss: 0.7190
Epoch 1/1
943/943 [==============================] - 0s 69us/step - loss: 0.6621
Epoch 1/1
950/950 [==============================] - 0s 67us/step - loss: 0.4314
Epoch 1/1
967/967 [==============================] - 0s 70us/step - loss: 0.4436
Epoch 1/1
954/954 [==============================] - 0s 68us/step - loss: 0.7180
Epoch 1/1
943/943 [==============================] - 0s 69us/step - loss: 0.6628
Epoch 1/1
950/950 [==============================] - 0s 69us/step - loss: 0.4327
Epoch 1/1
967/967 [==============================] - 0s 69us/step - loss: 0.4428
Epoch 1/1
954/954 [==============================] - 0s 69us/step - loss: 0.7208
Epoch 1/1
943/943 [==============================] - 0s 70us/step - loss: 0.6627
Epoch 1/1
950/950 [==============================] - 0s 72us/step - loss: 0.4299
Epoch 1/1
967/967 [==============================] - 0s 70us/step - loss: 0.4425
Epoch 1/1
954/954 [==============================] - 0s 67us/step - loss: 0.7160
Epoch 1/1
943/943 [==============================] - 0s 70us/step - loss: 0.6621
Epoch 1/1
950/950 [==============================] - 0s 67us/step - loss: 0.4316
Epoch 1/1
967/967 [==============================] - 0s 70us/step - loss: 0.4411
Epoch 1/1
954/954 [==============================] - 0s 66us/step - loss: 0.7161
Epoch 1/1
943/943 [==============================] - 0s 77us/step - loss: 0.6610
Epoch 1/1
950/950 [==============================] - 0s 67us/step - loss: 0.4321
Epoch 1/1
967/967 [==============================] - 0s 76us/step - loss: 0.4425
Epoch 1/1
954/954 [==============================] - 0s 68us/step - loss: 0.7162
Epoch 1/1
943/943 [==============================] - 0s 69us/step - loss: 0.6614
Epoch 1/1
950/950 [==============================] - 0s 69us/step - loss: 0.4321
Epoch 1/1
967/967 [==============================] - 0s 68us/step - loss: 0.4411
Epoch 1/1
954/954 [==============================] - 0s 67us/step - loss: 0.7175
Epoch 1/1
943/943 [==============================] - 0s 70us/step - loss: 0.6603
Epoch 1/1
950/950 [==============================] - 0s 66us/step - loss: 0.4306
Epoch 1/1
967/967 [==============================] - 0s 69us/step - loss: 0.4410
Epoch 1/1
954/954 [==============================] - 0s 71us/step - loss: 0.7171
Epoch 1/1
943/943 [==============================] - 0s 70us/step - loss: 0.6603
Epoch 1/1
950/950 [==============================] - 0s 68us/step - loss: 0.4281
Epoch 1/1
967/967 [==============================] - 0s 68us/step - loss: 0.4401
Epoch 1/1
954/954 [==============================] - 0s 68us/step - loss: 0.7167
Epoch 1/1
943/943 [==============================] - 0s 69us/step - loss: 0.6595
Epoch 1/1
950/950 [==============================] - 0s 69us/step - loss: 0.4312
Epoch 1/1
967/967 [==============================] - 0s 67us/step - loss: 0.4419
Epoch 1/1
954/954 [==============================] - 0s 69us/step - loss: 0.7181
Epoch 1/1
943/943 [==============================] - 0s 67us/step - loss: 0.6604
Epoch 1/1
950/950 [==============================] - 0s 71us/step - loss: 0.4307
Epoch 1/1
967/967 [==============================] - 0s 68us/step - loss: 0.4393
Epoch 1/1
954/954 [==============================] - 0s 67us/step - loss: 0.7159
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># alternate training discriminator and regressor                    </span>
<span class="k">for</span> <span class="n">n_epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">40</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">train_generator</span><span class="p">:</span>
        <span class="c1"># train discriminator</span>
        <span class="n">keras_model_reg</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">keras_model_disc</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">keras_model_adv</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">sgd_opt</span><span class="p">,</span> 
                        <span class="n">loss</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="s1">&#39;mse&#39;</span><span class="p">],</span>
                        <span class="n">loss_weights</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="n">lam</span><span class="p">])</span>    
        <span class="n">keras_model_adv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># train regressor</span>
        <span class="n">keras_model_reg</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">keras_model_disc</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">keras_model_reg</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">sgd_opt</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mse&#39;</span><span class="p">)</span>
        <span class="n">keras_model_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span><span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">keras_model_adv</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s1">&#39;keras_model_adv_best.h5&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1/1
943/943 [==============================] - 0s 484us/step - loss: 0.0788 - model_1_loss: 0.0788 - model_2_loss: 0.6502
Epoch 1/1
943/943 [==============================] - 0s 216us/step - loss: 0.6627
Epoch 1/1
950/950 [==============================] - 1s 540us/step - loss: 0.1175 - model_1_loss: 0.1179 - model_2_loss: 0.4309
Epoch 1/1
950/950 [==============================] - 0s 219us/step - loss: 0.4337
Epoch 1/1
967/967 [==============================] - 1s 524us/step - loss: 0.0863 - model_1_loss: 0.0847 - model_2_loss: 0.4352
Epoch 1/1
967/967 [==============================] - 0s 214us/step - loss: 0.4398
Epoch 1/1
954/954 [==============================] - 1s 528us/step - loss: 0.0844 - model_1_loss: 0.0854 - model_2_loss: 0.7173
Epoch 1/1
954/954 [==============================] - 0s 218us/step - loss: 0.7171
Epoch 1/1
943/943 [==============================] - 1s 531us/step - loss: 0.0809 - model_1_loss: 0.0809 - model_2_loss: 0.6818
Epoch 1/1
943/943 [==============================] - 0s 219us/step - loss: 0.6625
Epoch 1/1
950/950 [==============================] - 0s 522us/step - loss: 0.1121 - model_1_loss: 0.1128 - model_2_loss: 0.4284
Epoch 1/1
950/950 [==============================] - 0s 221us/step - loss: 0.4337
Epoch 1/1
967/967 [==============================] - 1s 527us/step - loss: 0.0803 - model_1_loss: 0.0791 - model_2_loss: 0.4404
Epoch 1/1
967/967 [==============================] - 0s 214us/step - loss: 0.4427
Epoch 1/1
954/954 [==============================] - 0s 522us/step - loss: 0.0804 - model_1_loss: 0.0807 - model_2_loss: 0.7220
Epoch 1/1
954/954 [==============================] - 0s 216us/step - loss: 0.7223
Epoch 1/1
943/943 [==============================] - 1s 532us/step - loss: 0.0858 - model_1_loss: 0.0862 - model_2_loss: 0.6577
Epoch 1/1
943/943 [==============================] - 0s 218us/step - loss: 0.6639
Epoch 1/1
950/950 [==============================] - 1s 540us/step - loss: 0.1037 - model_1_loss: 0.1057 - model_2_loss: 0.4332
Epoch 1/1
950/950 [==============================] - 0s 217us/step - loss: 0.4282
Epoch 1/1
967/967 [==============================] - 1s 519us/step - loss: 0.0802 - model_1_loss: 0.0799 - model_2_loss: 0.4324
Epoch 1/1
967/967 [==============================] - 0s 219us/step - loss: 0.4415
Epoch 1/1
954/954 [==============================] - 1s 526us/step - loss: 0.0818 - model_1_loss: 0.0831 - model_2_loss: 0.7251
Epoch 1/1
954/954 [==============================] - 0s 217us/step - loss: 0.7177
Epoch 1/1
943/943 [==============================] - 1s 535us/step - loss: 0.0820 - model_1_loss: 0.0854 - model_2_loss: 0.6585
Epoch 1/1
943/943 [==============================] - 0s 217us/step - loss: 0.6576
Epoch 1/1
950/950 [==============================] - 1s 526us/step - loss: 0.1014 - model_1_loss: 0.1009 - model_2_loss: 0.4297
Epoch 1/1
950/950 [==============================] - 0s 220us/step - loss: 0.4351
Epoch 1/1
967/967 [==============================] - 1s 528us/step - loss: 0.0787 - model_1_loss: 0.0774 - model_2_loss: 0.4339
Epoch 1/1
967/967 [==============================] - 0s 220us/step - loss: 0.4424
Epoch 1/1
954/954 [==============================] - 1s 528us/step - loss: 0.0752 - model_1_loss: 0.0756 - model_2_loss: 0.7200
Epoch 1/1
954/954 [==============================] - 0s 217us/step - loss: 0.7181
Epoch 1/1
943/943 [==============================] - 1s 531us/step - loss: 0.0865 - model_1_loss: 0.0866 - model_2_loss: 0.7174
Epoch 1/1
943/943 [==============================] - 0s 222us/step - loss: 0.6627
Epoch 1/1
950/950 [==============================] - 1s 545us/step - loss: 0.0975 - model_1_loss: 0.0972 - model_2_loss: 0.4317
Epoch 1/1
950/950 [==============================] - 0s 219us/step - loss: 0.4312
Epoch 1/1
967/967 [==============================] - 0s 512us/step - loss: 0.0843 - model_1_loss: 0.0907 - model_2_loss: 0.4326
Epoch 1/1
967/967 [==============================] - 0s 213us/step - loss: 0.4341
Epoch 1/1
954/954 [==============================] - 1s 531us/step - loss: 0.0848 - model_1_loss: 0.0857 - model_2_loss: 0.7184
Epoch 1/1
954/954 [==============================] - 0s 216us/step - loss: 0.7169
Epoch 1/1
943/943 [==============================] - 1s 549us/step - loss: 0.0744 - model_1_loss: 0.0749 - model_2_loss: 0.6517
Epoch 1/1
943/943 [==============================] - 0s 218us/step - loss: 0.6630
Epoch 1/1
950/950 [==============================] - 0s 517us/step - loss: 0.0953 - model_1_loss: 0.0953 - model_2_loss: 0.4297
Epoch 1/1
950/950 [==============================] - 0s 219us/step - loss: 0.4349
Epoch 1/1
967/967 [==============================] - 0s 515us/step - loss: 0.0820 - model_1_loss: 0.0804 - model_2_loss: 0.4761
Epoch 1/1
967/967 [==============================] - 0s 216us/step - loss: 0.4444
Epoch 1/1
954/954 [==============================] - 1s 532us/step - loss: 0.0784 - model_1_loss: 0.0797 - model_2_loss: 0.7356
Epoch 1/1
954/954 [==============================] - 0s 216us/step - loss: 0.7177
Epoch 1/1
943/943 [==============================] - 1s 545us/step - loss: 0.0854 - model_1_loss: 0.0846 - model_2_loss: 0.6517
Epoch 1/1
943/943 [==============================] - 0s 222us/step - loss: 0.6609
Epoch 1/1
950/950 [==============================] - 1s 534us/step - loss: 0.0958 - model_1_loss: 0.0958 - model_2_loss: 0.4278
Epoch 1/1
950/950 [==============================] - 0s 221us/step - loss: 0.4296
Epoch 1/1
967/967 [==============================] - 1s 518us/step - loss: 0.0754 - model_1_loss: 0.0768 - model_2_loss: 0.4429
Epoch 1/1
967/967 [==============================] - 0s 214us/step - loss: 0.4404
Epoch 1/1
954/954 [==============================] - 0s 522us/step - loss: 0.0754 - model_1_loss: 0.0758 - model_2_loss: 0.7188
Epoch 1/1
954/954 [==============================] - 0s 216us/step - loss: 0.7215
Epoch 1/1
943/943 [==============================] - 1s 551us/step - loss: 0.0695 - model_1_loss: 0.0708 - model_2_loss: 0.6651
Epoch 1/1
943/943 [==============================] - 0s 220us/step - loss: 0.6560
Epoch 1/1
950/950 [==============================] - 1s 530us/step - loss: 0.1047 - model_1_loss: 0.1045 - model_2_loss: 0.4259
Epoch 1/1
950/950 [==============================] - 0s 219us/step - loss: 0.4297
Epoch 1/1
967/967 [==============================] - 1s 530us/step - loss: 0.0822 - model_1_loss: 0.0814 - model_2_loss: 0.4336
Epoch 1/1
967/967 [==============================] - 0s 217us/step - loss: 0.4420
Epoch 1/1
954/954 [==============================] - 0s 521us/step - loss: 0.0800 - model_1_loss: 0.0811 - model_2_loss: 0.7173
Epoch 1/1
954/954 [==============================] - 0s 219us/step - loss: 0.7197
Epoch 1/1
943/943 [==============================] - 1s 532us/step - loss: 0.0806 - model_1_loss: 0.0820 - model_2_loss: 0.6529
Epoch 1/1
943/943 [==============================] - 0s 229us/step - loss: 0.6590
Epoch 1/1
950/950 [==============================] - 1s 532us/step - loss: 0.0986 - model_1_loss: 0.0986 - model_2_loss: 0.4302
Epoch 1/1
950/950 [==============================] - 0s 219us/step - loss: 0.4355
Epoch 1/1
967/967 [==============================] - 1s 530us/step - loss: 0.0889 - model_1_loss: 0.0872 - model_2_loss: 0.4370
Epoch 1/1
967/967 [==============================] - 0s 216us/step - loss: 0.4413
Epoch 1/1
954/954 [==============================] - 1s 536us/step - loss: 0.0743 - model_1_loss: 0.0750 - model_2_loss: 0.7176
Epoch 1/1
954/954 [==============================] - 0s 218us/step - loss: 0.7214
Epoch 1/1
943/943 [==============================] - 0s 522us/step - loss: 0.0804 - model_1_loss: 0.0802 - model_2_loss: 0.6517
Epoch 1/1
943/943 [==============================] - 0s 220us/step - loss: 0.6621
Epoch 1/1
950/950 [==============================] - 1s 541us/step - loss: 0.0961 - model_1_loss: 0.0960 - model_2_loss: 0.4290
Epoch 1/1
950/950 [==============================] - 0s 225us/step - loss: 0.4329
Epoch 1/1
967/967 [==============================] - 0s 515us/step - loss: 0.0786 - model_1_loss: 0.0774 - model_2_loss: 0.4339
Epoch 1/1
967/967 [==============================] - 0s 217us/step - loss: 0.4431
Epoch 1/1
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>954/954 [==============================] - 0s 523us/step - loss: 0.0834 - model_1_loss: 0.0840 - model_2_loss: 0.7164
Epoch 1/1
954/954 [==============================] - 0s 216us/step - loss: 0.7183
Epoch 1/1
943/943 [==============================] - 0s 528us/step - loss: 0.0812 - model_1_loss: 0.0847 - model_2_loss: 0.6508
Epoch 1/1
943/943 [==============================] - 0s 221us/step - loss: 0.6610
Epoch 1/1
950/950 [==============================] - 1s 527us/step - loss: 0.0973 - model_1_loss: 0.0973 - model_2_loss: 0.4377
Epoch 1/1
950/950 [==============================] - 0s 218us/step - loss: 0.4322
Epoch 1/1
967/967 [==============================] - 0s 516us/step - loss: 0.0810 - model_1_loss: 0.0801 - model_2_loss: 0.4335
Epoch 1/1
967/967 [==============================] - 0s 215us/step - loss: 0.4420
Epoch 1/1
954/954 [==============================] - 0s 521us/step - loss: 0.0791 - model_1_loss: 0.0798 - model_2_loss: 0.7224
Epoch 1/1
954/954 [==============================] - 0s 216us/step - loss: 0.7204
Epoch 1/1
943/943 [==============================] - 1s 545us/step - loss: 0.0773 - model_1_loss: 0.0770 - model_2_loss: 0.6646
Epoch 1/1
943/943 [==============================] - 0s 218us/step - loss: 0.6636
Epoch 1/1
950/950 [==============================] - 1s 529us/step - loss: 0.1065 - model_1_loss: 0.1068 - model_2_loss: 0.4320
Epoch 1/1
950/950 [==============================] - 0s 223us/step - loss: 0.4324
Epoch 1/1
967/967 [==============================] - 0s 516us/step - loss: 0.0787 - model_1_loss: 0.0773 - model_2_loss: 0.4328
Epoch 1/1
967/967 [==============================] - 0s 214us/step - loss: 0.4423
Epoch 1/1
954/954 [==============================] - 0s 515us/step - loss: 0.0767 - model_1_loss: 0.0776 - model_2_loss: 0.7270
Epoch 1/1
954/954 [==============================] - 0s 216us/step - loss: 0.7194
Epoch 1/1
943/943 [==============================] - 0s 527us/step - loss: 0.0783 - model_1_loss: 0.0820 - model_2_loss: 0.6506
Epoch 1/1
943/943 [==============================] - 0s 215us/step - loss: 0.6613
Epoch 1/1
950/950 [==============================] - 0s 521us/step - loss: 0.1060 - model_1_loss: 0.1057 - model_2_loss: 0.4355
Epoch 1/1
950/950 [==============================] - 0s 220us/step - loss: 0.4335
Epoch 1/1
967/967 [==============================] - 1s 518us/step - loss: 0.0810 - model_1_loss: 0.0802 - model_2_loss: 0.4370
Epoch 1/1
967/967 [==============================] - 0s 215us/step - loss: 0.4445
Epoch 1/1
954/954 [==============================] - 1s 539us/step - loss: 0.0788 - model_1_loss: 0.0795 - model_2_loss: 0.7210
Epoch 1/1
954/954 [==============================] - 0s 223us/step - loss: 0.7198
Epoch 1/1
943/943 [==============================] - 1s 544us/step - loss: 0.0842 - model_1_loss: 0.0838 - model_2_loss: 0.6511
Epoch 1/1
943/943 [==============================] - 0s 221us/step - loss: 0.6607
Epoch 1/1
950/950 [==============================] - 0s 523us/step - loss: 0.0941 - model_1_loss: 0.0954 - model_2_loss: 0.4276
Epoch 1/1
950/950 [==============================] - 0s 217us/step - loss: 0.4280
Epoch 1/1
967/967 [==============================] - 1s 524us/step - loss: 0.0760 - model_1_loss: 0.0857 - model_2_loss: 0.4483
Epoch 1/1
967/967 [==============================] - 0s 215us/step - loss: 0.4373
Epoch 1/1
954/954 [==============================] - 0s 523us/step - loss: 0.0783 - model_1_loss: 0.0796 - model_2_loss: 0.7187
Epoch 1/1
954/954 [==============================] - 0s 225us/step - loss: 0.7187
Epoch 1/1
943/943 [==============================] - 1s 544us/step - loss: 0.0774 - model_1_loss: 0.0771 - model_2_loss: 0.6601
Epoch 1/1
943/943 [==============================] - 0s 218us/step - loss: 0.6597
Epoch 1/1
950/950 [==============================] - 1s 542us/step - loss: 0.0908 - model_1_loss: 0.0917 - model_2_loss: 0.4308
Epoch 1/1
950/950 [==============================] - 0s 227us/step - loss: 0.4298
Epoch 1/1
967/967 [==============================] - 0s 516us/step - loss: 0.0814 - model_1_loss: 0.0832 - model_2_loss: 0.4322
Epoch 1/1
967/967 [==============================] - 0s 218us/step - loss: 0.4381
Epoch 1/1
954/954 [==============================] - 1s 538us/step - loss: 0.0761 - model_1_loss: 0.0773 - model_2_loss: 0.7264
Epoch 1/1
954/954 [==============================] - 0s 219us/step - loss: 0.7185
Epoch 1/1
943/943 [==============================] - 0s 528us/step - loss: 0.0777 - model_1_loss: 0.0824 - model_2_loss: 0.6991
Epoch 1/1
943/943 [==============================] - 0s 223us/step - loss: 0.6540
Epoch 1/1
950/950 [==============================] - 1s 528us/step - loss: 0.0939 - model_1_loss: 0.0939 - model_2_loss: 0.4315
Epoch 1/1
950/950 [==============================] - 0s 214us/step - loss: 0.4292
Epoch 1/1
967/967 [==============================] - 1s 523us/step - loss: 0.0814 - model_1_loss: 0.0830 - model_2_loss: 0.4747
Epoch 1/1
967/967 [==============================] - 0s 218us/step - loss: 0.4389
Epoch 1/1
954/954 [==============================] - 1s 530us/step - loss: 0.0787 - model_1_loss: 0.0794 - model_2_loss: 0.7211
Epoch 1/1
954/954 [==============================] - 0s 214us/step - loss: 0.7190
Epoch 1/1
943/943 [==============================] - 0s 527us/step - loss: 0.0735 - model_1_loss: 0.0749 - model_2_loss: 0.7001
Epoch 1/1
943/943 [==============================] - 0s 215us/step - loss: 0.6613
Epoch 1/1
950/950 [==============================] - 1s 530us/step - loss: 0.0916 - model_1_loss: 0.0917 - model_2_loss: 0.4299
Epoch 1/1
950/950 [==============================] - 0s 218us/step - loss: 0.4292
Epoch 1/1
967/967 [==============================] - 1s 519us/step - loss: 0.0813 - model_1_loss: 0.0799 - model_2_loss: 0.4331
Epoch 1/1
967/967 [==============================] - 0s 217us/step - loss: 0.4436
Epoch 1/1
954/954 [==============================] - 0s 524us/step - loss: 0.0777 - model_1_loss: 0.0787 - model_2_loss: 0.7173
Epoch 1/1
954/954 [==============================] - 0s 223us/step - loss: 0.7171
Epoch 1/1
943/943 [==============================] - 1s 536us/step - loss: 0.0741 - model_1_loss: 0.0745 - model_2_loss: 0.6531
Epoch 1/1
943/943 [==============================] - 0s 222us/step - loss: 0.6574
Epoch 1/1
950/950 [==============================] - 1s 533us/step - loss: 0.0869 - model_1_loss: 0.0868 - model_2_loss: 0.4270
Epoch 1/1
950/950 [==============================] - 0s 220us/step - loss: 0.4295
Epoch 1/1
967/967 [==============================] - 1s 524us/step - loss: 0.0820 - model_1_loss: 0.0828 - model_2_loss: 0.4330
Epoch 1/1
967/967 [==============================] - 0s 220us/step - loss: 0.4450
Epoch 1/1
954/954 [==============================] - 1s 533us/step - loss: 0.0897 - model_1_loss: 0.0933 - model_2_loss: 0.7206
Epoch 1/1
954/954 [==============================] - 0s 218us/step - loss: 0.7187
Epoch 1/1
943/943 [==============================] - 1s 534us/step - loss: 0.0721 - model_1_loss: 0.0720 - model_2_loss: 0.6482
Epoch 1/1
943/943 [==============================] - 0s 216us/step - loss: 0.6572
Epoch 1/1
950/950 [==============================] - 0s 520us/step - loss: 0.0974 - model_1_loss: 0.0970 - model_2_loss: 0.4326
Epoch 1/1
950/950 [==============================] - 0s 218us/step - loss: 0.4302
Epoch 1/1
967/967 [==============================] - 1s 522us/step - loss: 0.0789 - model_1_loss: 0.0782 - model_2_loss: 0.4340
Epoch 1/1
967/967 [==============================] - 0s 219us/step - loss: 0.4417
Epoch 1/1
954/954 [==============================] - 1s 529us/step - loss: 0.0799 - model_1_loss: 0.0801 - model_2_loss: 0.7172
Epoch 1/1
954/954 [==============================] - 0s 218us/step - loss: 0.7160
Epoch 1/1
943/943 [==============================] - 0s 530us/step - loss: 0.0763 - model_1_loss: 0.0762 - model_2_loss: 0.6574
Epoch 1/1
943/943 [==============================] - 0s 219us/step - loss: 0.6596
Epoch 1/1
950/950 [==============================] - 1s 542us/step - loss: 0.0904 - model_1_loss: 0.0901 - model_2_loss: 0.4359
Epoch 1/1
950/950 [==============================] - 0s 219us/step - loss: 0.4273
Epoch 1/1
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>967/967 [==============================] - 1s 527us/step - loss: 0.0783 - model_1_loss: 0.0771 - model_2_loss: 0.4328
Epoch 1/1
967/967 [==============================] - 0s 217us/step - loss: 0.4450
Epoch 1/1
954/954 [==============================] - 1s 536us/step - loss: 0.0773 - model_1_loss: 0.0778 - model_2_loss: 0.7350
Epoch 1/1
954/954 [==============================] - 0s 217us/step - loss: 0.7188
Epoch 1/1
943/943 [==============================] - 0s 529us/step - loss: 0.0721 - model_1_loss: 0.0730 - model_2_loss: 0.6613
Epoch 1/1
943/943 [==============================] - 0s 221us/step - loss: 0.6591
Epoch 1/1
950/950 [==============================] - 1s 536us/step - loss: 0.0950 - model_1_loss: 0.0957 - model_2_loss: 0.4288
Epoch 1/1
950/950 [==============================] - 0s 216us/step - loss: 0.4305
Epoch 1/1
967/967 [==============================] - 1s 521us/step - loss: 0.0744 - model_1_loss: 0.0730 - model_2_loss: 0.4363
Epoch 1/1
967/967 [==============================] - 0s 213us/step - loss: 0.4446
Epoch 1/1
954/954 [==============================] - 1s 538us/step - loss: 0.0805 - model_1_loss: 0.0815 - model_2_loss: 0.7189
Epoch 1/1
954/954 [==============================] - 0s 215us/step - loss: 0.7160
Epoch 1/1
943/943 [==============================] - 0s 516us/step - loss: 0.0742 - model_1_loss: 0.0740 - model_2_loss: 0.6497
Epoch 1/1
943/943 [==============================] - 0s 216us/step - loss: 0.6557
Epoch 1/1
950/950 [==============================] - 0s 519us/step - loss: 0.0926 - model_1_loss: 0.0923 - model_2_loss: 0.4260
Epoch 1/1
950/950 [==============================] - 0s 215us/step - loss: 0.4314
Epoch 1/1
967/967 [==============================] - 0s 513us/step - loss: 0.0795 - model_1_loss: 0.0779 - model_2_loss: 0.4345
Epoch 1/1
967/967 [==============================] - 0s 224us/step - loss: 0.4455
Epoch 1/1
954/954 [==============================] - 1s 541us/step - loss: 0.0793 - model_1_loss: 0.0796 - model_2_loss: 0.7151
Epoch 1/1
954/954 [==============================] - 0s 222us/step - loss: 0.7158
Epoch 1/1
943/943 [==============================] - 1s 533us/step - loss: 0.0765 - model_1_loss: 0.0766 - model_2_loss: 0.6569
Epoch 1/1
943/943 [==============================] - 0s 221us/step - loss: 0.6570
Epoch 1/1
950/950 [==============================] - 1s 532us/step - loss: 0.0961 - model_1_loss: 0.0959 - model_2_loss: 0.4230
Epoch 1/1
950/950 [==============================] - 0s 215us/step - loss: 0.4333
Epoch 1/1
967/967 [==============================] - 0s 513us/step - loss: 0.0796 - model_1_loss: 0.0884 - model_2_loss: 0.4721
Epoch 1/1
967/967 [==============================] - 0s 213us/step - loss: 0.4372
Epoch 1/1
954/954 [==============================] - 1s 531us/step - loss: 0.0815 - model_1_loss: 0.0818 - model_2_loss: 0.7345
Epoch 1/1
954/954 [==============================] - 0s 216us/step - loss: 0.7223
Epoch 1/1
943/943 [==============================] - 1s 543us/step - loss: 0.0895 - model_1_loss: 0.0890 - model_2_loss: 0.6544
Epoch 1/1
943/943 [==============================] - 0s 218us/step - loss: 0.6587
Epoch 1/1
950/950 [==============================] - 0s 526us/step - loss: 0.0931 - model_1_loss: 0.0928 - model_2_loss: 0.4287
Epoch 1/1
950/950 [==============================] - 0s 218us/step - loss: 0.4323
Epoch 1/1
967/967 [==============================] - 0s 516us/step - loss: 0.0807 - model_1_loss: 0.0794 - model_2_loss: 0.4329
Epoch 1/1
967/967 [==============================] - 0s 217us/step - loss: 0.4410
Epoch 1/1
954/954 [==============================] - 0s 523us/step - loss: 0.0739 - model_1_loss: 0.0754 - model_2_loss: 0.7206
Epoch 1/1
954/954 [==============================] - 0s 216us/step - loss: 0.7129
Epoch 1/1
943/943 [==============================] - 1s 536us/step - loss: 0.0757 - model_1_loss: 0.0754 - model_2_loss: 0.6529
Epoch 1/1
943/943 [==============================] - 0s 223us/step - loss: 0.6566
Epoch 1/1
950/950 [==============================] - 0s 523us/step - loss: 0.0959 - model_1_loss: 0.0955 - model_2_loss: 0.4316
Epoch 1/1
950/950 [==============================] - 0s 217us/step - loss: 0.4304
Epoch 1/1
967/967 [==============================] - 1s 541us/step - loss: 0.0747 - model_1_loss: 0.0733 - model_2_loss: 0.4898
Epoch 1/1
967/967 [==============================] - 0s 218us/step - loss: 0.4387
Epoch 1/1
954/954 [==============================] - 1s 525us/step - loss: 0.0777 - model_1_loss: 0.0785 - model_2_loss: 0.7152
Epoch 1/1
954/954 [==============================] - 0s 213us/step - loss: 0.7184
Epoch 1/1
943/943 [==============================] - 1s 534us/step - loss: 0.0714 - model_1_loss: 0.0711 - model_2_loss: 0.6551
Epoch 1/1
943/943 [==============================] - 0s 218us/step - loss: 0.6560
Epoch 1/1
950/950 [==============================] - 0s 525us/step - loss: 0.1003 - model_1_loss: 0.1001 - model_2_loss: 0.4338
Epoch 1/1
950/950 [==============================] - 0s 215us/step - loss: 0.4306
Epoch 1/1
967/967 [==============================] - 0s 511us/step - loss: 0.0794 - model_1_loss: 0.0862 - model_2_loss: 0.4318
Epoch 1/1
967/967 [==============================] - 0s 214us/step - loss: 0.4362
Epoch 1/1
954/954 [==============================] - 0s 518us/step - loss: 0.0721 - model_1_loss: 0.0733 - model_2_loss: 0.7260
Epoch 1/1
954/954 [==============================] - 0s 213us/step - loss: 0.7124
Epoch 1/1
943/943 [==============================] - 0s 525us/step - loss: 0.0699 - model_1_loss: 0.0699 - model_2_loss: 0.6485
Epoch 1/1
943/943 [==============================] - 0s 219us/step - loss: 0.6592
Epoch 1/1
950/950 [==============================] - 1s 534us/step - loss: 0.0952 - model_1_loss: 0.0950 - model_2_loss: 0.4286
Epoch 1/1
950/950 [==============================] - 0s 220us/step - loss: 0.4331
Epoch 1/1
967/967 [==============================] - 1s 519us/step - loss: 0.0711 - model_1_loss: 0.0698 - model_2_loss: 0.4361
Epoch 1/1
967/967 [==============================] - 0s 213us/step - loss: 0.4421
Epoch 1/1
954/954 [==============================] - 0s 519us/step - loss: 0.0712 - model_1_loss: 0.0717 - model_2_loss: 0.7204
Epoch 1/1
954/954 [==============================] - 0s 211us/step - loss: 0.7202
Epoch 1/1
943/943 [==============================] - 1s 539us/step - loss: 0.0752 - model_1_loss: 0.0763 - model_2_loss: 0.6549
Epoch 1/1
943/943 [==============================] - 0s 218us/step - loss: 0.6646
Epoch 1/1
950/950 [==============================] - 1s 534us/step - loss: 0.0937 - model_1_loss: 0.0960 - model_2_loss: 0.4292
Epoch 1/1
950/950 [==============================] - 0s 229us/step - loss: 0.4317
Epoch 1/1
967/967 [==============================] - 1s 535us/step - loss: 0.0769 - model_1_loss: 0.0774 - model_2_loss: 0.4322
Epoch 1/1
967/967 [==============================] - 0s 222us/step - loss: 0.4389
Epoch 1/1
954/954 [==============================] - 1s 544us/step - loss: 0.0739 - model_1_loss: 0.0744 - model_2_loss: 0.7169
Epoch 1/1
954/954 [==============================] - 0s 219us/step - loss: 0.7188
Epoch 1/1
943/943 [==============================] - 0s 525us/step - loss: 0.0757 - model_1_loss: 0.0834 - model_2_loss: 0.6492
Epoch 1/1
943/943 [==============================] - 0s 222us/step - loss: 0.6566
Epoch 1/1
950/950 [==============================] - 0s 525us/step - loss: 0.0872 - model_1_loss: 0.0869 - model_2_loss: 0.4286
Epoch 1/1
950/950 [==============================] - 0s 217us/step - loss: 0.4309
Epoch 1/1
967/967 [==============================] - 1s 517us/step - loss: 0.0743 - model_1_loss: 0.0733 - model_2_loss: 0.4510
Epoch 1/1
967/967 [==============================] - 0s 216us/step - loss: 0.4405
Epoch 1/1
954/954 [==============================] - 1s 525us/step - loss: 0.0749 - model_1_loss: 0.0752 - model_2_loss: 0.7287
Epoch 1/1
954/954 [==============================] - 0s 223us/step - loss: 0.7131
Epoch 1/1
943/943 [==============================] - 1s 537us/step - loss: 0.0716 - model_1_loss: 0.0713 - model_2_loss: 0.6533
Epoch 1/1
943/943 [==============================] - 0s 223us/step - loss: 0.6599
Epoch 1/1
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>950/950 [==============================] - 0s 524us/step - loss: 0.0917 - model_1_loss: 0.0917 - model_2_loss: 0.4286
Epoch 1/1
950/950 [==============================] - 0s 219us/step - loss: 0.4322
Epoch 1/1
967/967 [==============================] - 0s 512us/step - loss: 0.0749 - model_1_loss: 0.0736 - model_2_loss: 0.4314
Epoch 1/1
967/967 [==============================] - 0s 212us/step - loss: 0.4365
Epoch 1/1
954/954 [==============================] - 0s 521us/step - loss: 0.0694 - model_1_loss: 0.0704 - model_2_loss: 0.7172
Epoch 1/1
954/954 [==============================] - 0s 216us/step - loss: 0.7136
Epoch 1/1
943/943 [==============================] - 1s 535us/step - loss: 0.0609 - model_1_loss: 0.0607 - model_2_loss: 0.6569
Epoch 1/1
943/943 [==============================] - 0s 221us/step - loss: 0.6576
Epoch 1/1
950/950 [==============================] - 1s 528us/step - loss: 0.0923 - model_1_loss: 0.0979 - model_2_loss: 0.4362
Epoch 1/1
950/950 [==============================] - 0s 226us/step - loss: 0.4274
Epoch 1/1
967/967 [==============================] - 1s 526us/step - loss: 0.0765 - model_1_loss: 0.0751 - model_2_loss: 0.4306
Epoch 1/1
967/967 [==============================] - 0s 217us/step - loss: 0.4404
Epoch 1/1
954/954 [==============================] - 1s 533us/step - loss: 0.0772 - model_1_loss: 0.0783 - model_2_loss: 0.7145
Epoch 1/1
954/954 [==============================] - 0s 219us/step - loss: 0.7172
Epoch 1/1
943/943 [==============================] - 1s 536us/step - loss: 0.0738 - model_1_loss: 0.0748 - model_2_loss: 0.6477
Epoch 1/1
943/943 [==============================] - 0s 217us/step - loss: 0.6579
Epoch 1/1
950/950 [==============================] - 1s 528us/step - loss: 0.0893 - model_1_loss: 0.0894 - model_2_loss: 0.4245
Epoch 1/1
950/950 [==============================] - 0s 217us/step - loss: 0.4301
Epoch 1/1
967/967 [==============================] - 1s 531us/step - loss: 0.0806 - model_1_loss: 0.0790 - model_2_loss: 0.4316
Epoch 1/1
967/967 [==============================] - 0s 213us/step - loss: 0.4432
Epoch 1/1
954/954 [==============================] - 0s 524us/step - loss: 0.0751 - model_1_loss: 0.0778 - model_2_loss: 0.7192
Epoch 1/1
954/954 [==============================] - 0s 218us/step - loss: 0.7067
Epoch 1/1
943/943 [==============================] - 0s 521us/step - loss: 0.0714 - model_1_loss: 0.0744 - model_2_loss: 0.6598
Epoch 1/1
943/943 [==============================] - 0s 217us/step - loss: 0.6612
Epoch 1/1
950/950 [==============================] - 0s 515us/step - loss: 0.0905 - model_1_loss: 0.0919 - model_2_loss: 0.4333
Epoch 1/1
950/950 [==============================] - 0s 215us/step - loss: 0.4291
Epoch 1/1
967/967 [==============================] - 1s 521us/step - loss: 0.0718 - model_1_loss: 0.0724 - model_2_loss: 0.4325
Epoch 1/1
967/967 [==============================] - 0s 213us/step - loss: 0.4412
Epoch 1/1
954/954 [==============================] - 0s 515us/step - loss: 0.0814 - model_1_loss: 0.0822 - model_2_loss: 0.7157
Epoch 1/1
954/954 [==============================] - 0s 214us/step - loss: 0.7153
Epoch 1/1
943/943 [==============================] - 0s 518us/step - loss: 0.0788 - model_1_loss: 0.0787 - model_2_loss: 0.6510
Epoch 1/1
943/943 [==============================] - 0s 216us/step - loss: 0.6621
Epoch 1/1
950/950 [==============================] - 1s 529us/step - loss: 0.0982 - model_1_loss: 0.0980 - model_2_loss: 0.4280
Epoch 1/1
950/950 [==============================] - 0s 217us/step - loss: 0.4325
Epoch 1/1
967/967 [==============================] - 1s 525us/step - loss: 0.0714 - model_1_loss: 0.0713 - model_2_loss: 0.4333
Epoch 1/1
967/967 [==============================] - 0s 224us/step - loss: 0.4408
Epoch 1/1
954/954 [==============================] - 1s 525us/step - loss: 0.0711 - model_1_loss: 0.0717 - model_2_loss: 0.7129
Epoch 1/1
954/954 [==============================] - 0s 217us/step - loss: 0.7209
Epoch 1/1
943/943 [==============================] - 1s 533us/step - loss: 0.0720 - model_1_loss: 0.0715 - model_2_loss: 0.7013
Epoch 1/1
943/943 [==============================] - 0s 224us/step - loss: 0.6566
Epoch 1/1
950/950 [==============================] - 0s 523us/step - loss: 0.0892 - model_1_loss: 0.0898 - model_2_loss: 0.4479
Epoch 1/1
950/950 [==============================] - 0s 215us/step - loss: 0.4325
Epoch 1/1
967/967 [==============================] - 0s 512us/step - loss: 0.0764 - model_1_loss: 0.0750 - model_2_loss: 0.4353
Epoch 1/1
967/967 [==============================] - 0s 218us/step - loss: 0.4426
Epoch 1/1
954/954 [==============================] - 1s 526us/step - loss: 0.0803 - model_1_loss: 0.0808 - model_2_loss: 0.7158
Epoch 1/1
954/954 [==============================] - 0s 219us/step - loss: 0.7122
Epoch 1/1
943/943 [==============================] - 0s 514us/step - loss: 0.0729 - model_1_loss: 0.0740 - model_2_loss: 0.6442
Epoch 1/1
943/943 [==============================] - 0s 218us/step - loss: 0.6596
Epoch 1/1
950/950 [==============================] - 1s 531us/step - loss: 0.0906 - model_1_loss: 0.0901 - model_2_loss: 0.4261
Epoch 1/1
950/950 [==============================] - 0s 214us/step - loss: 0.4280
Epoch 1/1
967/967 [==============================] - 0s 510us/step - loss: 0.0729 - model_1_loss: 0.0716 - model_2_loss: 0.4326
Epoch 1/1
967/967 [==============================] - 0s 217us/step - loss: 0.4383
Epoch 1/1
954/954 [==============================] - 0s 523us/step - loss: 0.0717 - model_1_loss: 0.0721 - model_2_loss: 0.7287
Epoch 1/1
954/954 [==============================] - 0s 215us/step - loss: 0.7179
Epoch 1/1
943/943 [==============================] - 0s 520us/step - loss: 0.0772 - model_1_loss: 0.0768 - model_2_loss: 0.6470
Epoch 1/1
943/943 [==============================] - 0s 215us/step - loss: 0.6579
Epoch 1/1
950/950 [==============================] - 0s 525us/step - loss: 0.0880 - model_1_loss: 0.0883 - model_2_loss: 0.4311
Epoch 1/1
950/950 [==============================] - 0s 214us/step - loss: 0.4311
Epoch 1/1
967/967 [==============================] - 1s 531us/step - loss: 0.0689 - model_1_loss: 0.0677 - model_2_loss: 0.4306
Epoch 1/1
967/967 [==============================] - 0s 212us/step - loss: 0.4380
Epoch 1/1
954/954 [==============================] - 1s 529us/step - loss: 0.0645 - model_1_loss: 0.0659 - model_2_loss: 0.7189
Epoch 1/1
954/954 [==============================] - 0s 217us/step - loss: 0.7136
Epoch 1/1
943/943 [==============================] - 1s 532us/step - loss: 0.0707 - model_1_loss: 0.0731 - model_2_loss: 0.6708
Epoch 1/1
943/943 [==============================] - 0s 222us/step - loss: 0.6466
Epoch 1/1
950/950 [==============================] - 1s 536us/step - loss: 0.0962 - model_1_loss: 0.0970 - model_2_loss: 0.4246
Epoch 1/1
950/950 [==============================] - 0s 219us/step - loss: 0.4273
Epoch 1/1
967/967 [==============================] - 1s 521us/step - loss: 0.0692 - model_1_loss: 0.0715 - model_2_loss: 0.4307
Epoch 1/1
967/967 [==============================] - 0s 217us/step - loss: 0.4447
Epoch 1/1
954/954 [==============================] - 0s 516us/step - loss: 0.0717 - model_1_loss: 0.0726 - model_2_loss: 0.7206
Epoch 1/1
954/954 [==============================] - 0s 218us/step - loss: 0.7179
Epoch 1/1
943/943 [==============================] - 0s 521us/step - loss: 0.0745 - model_1_loss: 0.0741 - model_2_loss: 0.6527
Epoch 1/1
943/943 [==============================] - 0s 219us/step - loss: 0.6577
Epoch 1/1
950/950 [==============================] - 0s 514us/step - loss: 0.0892 - model_1_loss: 0.0890 - model_2_loss: 0.4339
Epoch 1/1
950/950 [==============================] - 0s 214us/step - loss: 0.4329
Epoch 1/1
967/967 [==============================] - 1s 525us/step - loss: 0.0731 - model_1_loss: 0.0729 - model_2_loss: 0.4326
Epoch 1/1
967/967 [==============================] - 0s 214us/step - loss: 0.4434
Epoch 1/1
954/954 [==============================] - 0s 517us/step - loss: 0.0676 - model_1_loss: 0.0680 - model_2_loss: 0.7278
Epoch 1/1
954/954 [==============================] - 0s 212us/step - loss: 0.7160
Epoch 1/1
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>943/943 [==============================] - 0s 524us/step - loss: 0.0672 - model_1_loss: 0.0669 - model_2_loss: 0.6595
Epoch 1/1
943/943 [==============================] - 0s 214us/step - loss: 0.6518
Epoch 1/1
950/950 [==============================] - 0s 511us/step - loss: 0.0914 - model_1_loss: 0.0916 - model_2_loss: 0.4286
Epoch 1/1
950/950 [==============================] - 0s 218us/step - loss: 0.4326
Epoch 1/1
967/967 [==============================] - 0s 513us/step - loss: 0.0753 - model_1_loss: 0.0749 - model_2_loss: 0.4385
Epoch 1/1
967/967 [==============================] - 0s 214us/step - loss: 0.4393
Epoch 1/1
954/954 [==============================] - 0s 518us/step - loss: 0.0736 - model_1_loss: 0.0740 - model_2_loss: 0.7214
Epoch 1/1
954/954 [==============================] - 0s 218us/step - loss: 0.7209
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># load testing file</span>
<span class="n">test_files</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;root://eospublic.cern.ch//eos/opendata/cms/datascience/HiggsToBBNtupleProducerTool/HiggsToBBNTuple_HiggsToBB_QCD_RunII_13TeV_MC/test/ntuple_merged_0.root&#39;</span>
             <span class="p">]</span>
<span class="n">test_generator</span> <span class="o">=</span> <span class="n">DataGenerator</span><span class="p">(</span><span class="n">test_files</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">spectators</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">8192</span><span class="p">,</span> <span class="n">n_dim</span><span class="o">=</span><span class="n">ntracks</span><span class="p">,</span> 
                               <span class="n">remove_mass_pt_window</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                               <span class="n">remove_unlabeled</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">return_spectators</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">max_entry</span> <span class="o">=</span> <span class="mi">200000</span><span class="p">)</span> <span class="c1"># basically, no maximum</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tqdm</span>
<span class="c1"># run model inference on test data set</span>
<span class="n">predict_array_adv</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">label_array_test</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">spec_array_test</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="o">.</span><span class="n">tqdm</span><span class="p">(</span><span class="n">test_generator</span><span class="p">,</span><span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">test_generator</span><span class="p">)):</span>
    <span class="n">label_array_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">spec_array_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">predict_array_adv</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">keras_model_adv</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">predict_array_adv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">predict_array_adv</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">label_array_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">label_array_test</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">spec_array_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">spec_array_test</span><span class="p">,</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 24/24 [02:56&lt;00:00,  7.37s/it]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># create ROC curves</span>
<span class="nb">print</span><span class="p">(</span><span class="n">label_array_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">spec_array_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">predict_array_adv</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">fpr_adv</span><span class="p">,</span> <span class="n">tpr_adv</span><span class="p">,</span> <span class="n">threshold_adv</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">label_array_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">predict_array_adv</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
    
<span class="c1"># plot ROC curves</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">tpr_adv</span><span class="p">,</span> <span class="n">fpr_adv</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Adversarial, AUC = </span><span class="si">{:.1f}</span><span class="s2">%&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr_adv</span><span class="p">,</span><span class="n">tpr_adv</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;True positive rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;False positive rate&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(61968, 2)
(61968, 2)
(61968, 2)
</pre></div>
</div>
<img alt="../_images/07-objectives_11_1.png" src="../_images/07-objectives_11_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">find_nearest</span><span class="p">(</span><span class="n">array</span><span class="p">,</span><span class="n">value</span><span class="p">):</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">array</span><span class="o">-</span><span class="n">value</span><span class="p">))</span><span class="o">.</span><span class="n">argmin</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">idx</span><span class="p">,</span> <span class="n">array</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="k">for</span> <span class="n">wp</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]:</span>
    <span class="n">idx</span><span class="p">,</span> <span class="n">val</span> <span class="o">=</span> <span class="n">find_nearest</span><span class="p">(</span><span class="n">fpr_adv</span><span class="p">,</span> <span class="n">wp</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">spec_array_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">21</span><span class="p">),</span> 
             <span class="n">weights</span> <span class="o">=</span> <span class="n">label_array_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">predict_array_adv</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold_adv</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span>
             <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;QCD, </span><span class="si">{}% F</span><span class="s1">PR cut&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">wp</span><span class="o">*</span><span class="mi">100</span><span class="p">)),</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$m_</span><span class="si">{SD}</span><span class="s1">$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Normalized probability&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="k">for</span> <span class="n">wp</span> <span class="ow">in</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]:</span>
    <span class="n">idx</span><span class="p">,</span> <span class="n">val</span> <span class="o">=</span> <span class="n">find_nearest</span><span class="p">(</span><span class="n">fpr_adv</span><span class="p">,</span> <span class="n">wp</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">spec_array_test</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">21</span><span class="p">),</span> 
             <span class="n">weights</span> <span class="o">=</span> <span class="n">label_array_test</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="n">predict_array_adv</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold_adv</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span>
             <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;H(bb), </span><span class="si">{}% F</span><span class="s1">PR cut&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">wp</span><span class="o">*</span><span class="mi">100</span><span class="p">)),</span><span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$m_</span><span class="si">{SD}</span><span class="s1">$&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;Normalized probability&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span><span class="mi">200</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/07-objectives_13_0.png" src="../_images/07-objectives_13_0.png" />
<img alt="../_images/07-objectives_13_1.png" src="../_images/07-objectives_13_1.png" />
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./weeks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="07.html" title="previous page">Week 7: Optimizing Other Objectives</a>
    <a class='right-next' id="next-link" href="08.html" title="next page">Week 8: Extending the Model</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Javier Duarte and Frank Würthwein<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>